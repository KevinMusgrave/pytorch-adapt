{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "85bf6121",
      "metadata": {
        "id": "85bf6121",
        "outputId": "9d9f6ee0-32ec-4efc-eb15-77c18883b1e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-adapt\n",
            "  Downloading pytorch_adapt-0.0.61-py3-none-any.whl (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 12.4 MB/s \n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n",
            "\u001b[K     |████████████████████████████████| 397 kB 29.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.10.0+cu111)\n",
            "Collecting pytorch-metric-learning>=1.1.0\n",
            "  Downloading pytorch_metric_learning-1.2.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-adapt) (3.10.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics->pytorch-adapt) (21.3)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics->pytorch-adapt) (3.0.7)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-adapt) (7.1.2)\n",
            "Installing collected packages: pyDeprecate, torchmetrics, pytorch-metric-learning, pytorch-adapt\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-adapt-0.0.61 pytorch-metric-learning-1.2.0 torchmetrics-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-adapt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a83b07",
      "metadata": {
        "id": "64a83b07"
      },
      "source": [
        "### Inputs to hooks\n",
        "Every hook takes in 2 arguments that represent the current context:\n",
        "\n",
        "- A dictionary of models and tensors.\n",
        "- An optional dictionary of losses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f30a44",
      "metadata": {
        "id": "12f30a44"
      },
      "source": [
        "### FeaturesHook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5a58f4a5",
      "metadata": {
        "id": "5a58f4a5",
        "outputId": "317cb30d-91b6-45a8-8e2e-295c79c90ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs ['src_imgs', 'target_imgs']\n",
            "Outputs ['src_imgs_features', 'target_imgs_features']\n",
            "G.count = 2\n",
            "\n",
            "Inputs ['src_imgs', 'target_imgs', 'src_imgs_features', 'target_imgs_features']\n",
            "Outputs []\n",
            "G.count = 2\n",
            "\n",
            "Inputs ['src_imgs', 'target_imgs', 'src_imgs_features', 'target_imgs_features']\n",
            "Outputs ['src_imgs_features_detached', 'target_imgs_features_detached']\n",
            "G.count = 2\n",
            "\n",
            "Inputs ['src_imgs', 'target_imgs']\n",
            "Outputs ['src_imgs_features_detached', 'target_imgs_features_detached']\n",
            "G.count = 4\n",
            "\n",
            "Inputs ['src_imgs', 'target_imgs', 'src_imgs_features_detached', 'target_imgs_features_detached']\n",
            "Outputs ['src_imgs_features', 'target_imgs_features']\n",
            "G.count = 6\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "from pytorch_adapt.hooks import FeaturesHook\n",
        "\n",
        "\n",
        "def forward_count(self, *_):\n",
        "    self.count += 1\n",
        "\n",
        "\n",
        "def print_keys_and_count(inputs, outputs, models):\n",
        "    print(\"Inputs\", list(inputs.keys()))\n",
        "    print(\"Outputs\", list(outputs.keys()))\n",
        "    for k, v in models.items():\n",
        "        print(f\"{k}.count = {v.count}\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "G = torch.nn.Linear(1000, 100)\n",
        "G.register_forward_hook(forward_count)\n",
        "G.count = 0\n",
        "\n",
        "models = {\"G\": G}\n",
        "data = {\n",
        "    \"src_imgs\": torch.randn(32, 1000),\n",
        "    \"target_imgs\": torch.randn(32, 1000),\n",
        "}\n",
        "\n",
        "hook = FeaturesHook()\n",
        "\n",
        "inputs = data\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "# Outputs contains src_imgs_features and target_imgs_features.\n",
        "print_keys_and_count(inputs, outputs, models)\n",
        "\n",
        "inputs = {**data, **outputs}\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "# Outputs is empty because the required outputs are already in the inputs.\n",
        "# G.count remains the same because G wasn't used for anything.\n",
        "print_keys_and_count(inputs, outputs, models)\n",
        "\n",
        "hook = FeaturesHook(detach=True)\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "# Detached data is kept separate.\n",
        "# G.count remains the same because the existing tensors\n",
        "# were simply detached, and this requires no computation.\n",
        "print_keys_and_count(inputs, outputs, models)\n",
        "\n",
        "inputs = data\n",
        "hook = FeaturesHook(detach=True)\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "# G.count increases because the undetached data wasn't passed in\n",
        "# so it has to be computed\n",
        "print_keys_and_count(inputs, outputs, models)\n",
        "\n",
        "inputs = {**data, **outputs}\n",
        "hook = FeaturesHook()\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "# Even though detached data is passed in,\n",
        "# G.count increases because you can't get undetached data from detached data\n",
        "print_keys_and_count(inputs, outputs, models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f3d1ea",
      "metadata": {
        "id": "05f3d1ea"
      },
      "source": [
        "### LogitsHook\n",
        "\n",
        "```LogitsHook``` works the same as ```FeaturesHook```, but expects features as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "458726af",
      "metadata": {
        "id": "458726af",
        "outputId": "156a582b-4a31-450d-f537-4bc8e5eaf6c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs ['src_imgs_features', 'target_imgs_features']\n",
            "Outputs ['src_imgs_features_logits', 'target_imgs_features_logits']\n",
            "C.count = 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import LogitsHook\n",
        "\n",
        "C = torch.nn.Linear(100, 10)\n",
        "C.register_forward_hook(forward_count)\n",
        "C.count = 0\n",
        "\n",
        "models = {\"C\": C}\n",
        "data = {\n",
        "    \"src_imgs_features\": torch.randn(32, 100),\n",
        "    \"target_imgs_features\": torch.randn(32, 100),\n",
        "}\n",
        "hook = LogitsHook()\n",
        "\n",
        "inputs = data\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "print_keys_and_count(inputs, outputs, models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8257928",
      "metadata": {
        "id": "c8257928"
      },
      "source": [
        "### FeaturesAndLogitsHook\n",
        "\n",
        "```FeaturesAndLogitsHook``` combines ```FeaturesHook``` and ```LogitsHook```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0dd4ec18",
      "metadata": {
        "id": "0dd4ec18",
        "outputId": "622b689c-5a33-4510-e483-6de5a52f6308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs ['src_imgs', 'target_imgs']\n",
            "Outputs ['src_imgs_features', 'target_imgs_features', 'src_imgs_features_logits', 'target_imgs_features_logits']\n",
            "G.count = 2\n",
            "C.count = 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import FeaturesAndLogitsHook\n",
        "\n",
        "G.count, C.count = 0, 0\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = {\n",
        "    \"src_imgs\": torch.randn(32, 1000),\n",
        "    \"target_imgs\": torch.randn(32, 1000),\n",
        "}\n",
        "hook = FeaturesAndLogitsHook()\n",
        "\n",
        "inputs = data\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "print_keys_and_count(inputs, outputs, models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ccd7789",
      "metadata": {
        "id": "3ccd7789"
      },
      "source": [
        "### ChainHook\n",
        "\n",
        "```ChainHook``` allows you to chain together an arbitrary number of hooks. The hooks are run sequentially, with the outputs of hook ```n``` being added to the context so that they become part of the inputs to hook ```n+1```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a856c4a3",
      "metadata": {
        "id": "a856c4a3",
        "outputId": "e3845d1c-a7b4-45f0-c0fd-13cb0ce8ba2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs ['src_imgs', 'target_imgs']\n",
            "Outputs ['src_imgs_features', 'target_imgs_features', 'src_imgs_features_logits', 'target_imgs_features_logits']\n",
            "G.count = 2\n",
            "C.count = 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import ChainHook\n",
        "\n",
        "G.count, C.count = 0, 0\n",
        "hook = ChainHook(FeaturesHook(), LogitsHook())\n",
        "\n",
        "inputs = data\n",
        "outputs, losses = hook({**models, **inputs})\n",
        "print_keys_and_count(inputs, outputs, models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "28d4dd1d",
      "metadata": {
        "id": "28d4dd1d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Hooks.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}