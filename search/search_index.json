{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyTorch Adapt \u00b6 Google Colab Examples \u00b6 Overview \u00b6 Installation \u00b6 Pip \u00b6 pip install pytorch-adapt To get the latest dev version : pip install pytorch-adapt --pre","title":"Overview"},{"location":"#pytorch-adapt","text":"","title":"PyTorch Adapt"},{"location":"#google-colab-examples","text":"","title":"Google Colab Examples"},{"location":"#overview","text":"","title":"Overview"},{"location":"#installation","text":"","title":"Installation"},{"location":"#pip","text":"pip install pytorch-adapt To get the latest dev version : pip install pytorch-adapt --pre","title":"Pip"},{"location":"SUMMARY/","text":"Overview Hooks Base Utils","title":"SUMMARY"},{"location":"adapters/","text":"Adapters \u00b6","title":"Adapters"},{"location":"adapters/#adapters","text":"","title":"Adapters"},{"location":"containers/","text":"Containers \u00b6","title":"Containers"},{"location":"containers/#containers","text":"","title":"Containers"},{"location":"datasets/","text":"Datasets \u00b6","title":"Datasets"},{"location":"datasets/#datasets","text":"","title":"Datasets"},{"location":"frameworks/","text":"Frameworks \u00b6","title":"Frameworks"},{"location":"frameworks/#frameworks","text":"","title":"Frameworks"},{"location":"layers/","text":"Layers \u00b6","title":"Layers"},{"location":"layers/#layers","text":"","title":"Layers"},{"location":"meta_validators/","text":"Meta Validators \u00b6","title":"Meta Validators"},{"location":"meta_validators/#meta-validators","text":"","title":"Meta Validators"},{"location":"models/","text":"Models \u00b6","title":"Models"},{"location":"models/#models","text":"","title":"Models"},{"location":"utils/","text":"Utils \u00b6","title":"Utils"},{"location":"utils/#utils","text":"","title":"Utils"},{"location":"validators/","text":"Validators \u00b6","title":"Validators"},{"location":"validators/#validators","text":"","title":"Validators"},{"location":"weighters/","text":"Weighters \u00b6","title":"Weighters"},{"location":"weighters/#weighters","text":"","title":"Weighters"},{"location":"hooks/","text":"Hooks \u00b6 Hooks are the main building block of this library. Every hook is a callable that takes in 2 arguments that represent the current context: A dictionary of previously computed losses. A dictionary of everything else that has been previously computed or passed in. The purpose of the context is to compute data only when necessary. For example, to compute a classification loss, a hook will need logits. If these logits are not available in the context, then they are computed, added to the context, and then used to compute the loss. If they are already in the context, then only the loss is computed.","title":"Hooks"},{"location":"hooks/#hooks","text":"Hooks are the main building block of this library. Every hook is a callable that takes in 2 arguments that represent the current context: A dictionary of previously computed losses. A dictionary of everything else that has been previously computed or passed in. The purpose of the context is to compute data only when necessary. For example, to compute a classification loss, a hook will need logits. If these logits are not available in the context, then they are computed, added to the context, and then used to compute the loss. If they are already in the context, then only the loss is computed.","title":"Hooks"},{"location":"hooks/base/","text":"pytorch_adapt.hooks.base \u00b6 BaseConditionHook \u00b6 The base class for hooks that return a boolean BaseHook \u00b6 All hooks extend BaseHook __init__ ( self , loss_prefix = '' , loss_suffix = '' , out_prefix = '' , out_suffix = '' , key_map = None ) special \u00b6 Parameters: Name Type Description Default loss_prefix str prepended to all new loss keys '' loss_suffix str appended to all new loss keys '' out_prefix str prepended to all new output keys '' out_suffix str appended to all new output keys '' key_map Dict[str, str] a mapping from input_key to new_key . For example, if key_map = {\"A\": \"B\"}, and the input dict to __call__ is {\"A\": 5}, then the input will be converted to {\"B\": 5} before being consumed. Before exiting __call__ , the mapping is undone so the input context is preserved. In other words, {\"B\": 5} will be converted back to {\"A\": 5}. None Source code in pytorch_adapt\\hooks\\base.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def __init__ ( self , loss_prefix : str = \"\" , loss_suffix : str = \"\" , out_prefix : str = \"\" , out_suffix : str = \"\" , key_map : Dict [ str , str ] = None , ): \"\"\" Arguments: loss_prefix: prepended to all new loss keys loss_suffix: appended to all new loss keys out_prefix: prepended to all new output keys out_suffix: appended to all new output keys key_map: a mapping from ```input_key``` to ```new_key```. For example, if key_map = {\"A\": \"B\"}, and the input dict to ```__call__``` is {\"A\": 5}, then the input will be converted to {\"B\": 5} before being consumed. Before exiting ```__call__```, the mapping is undone so the input context is preserved. In other words, {\"B\": 5} will be converted back to {\"A\": 5}. \"\"\" if any ( not isinstance ( x , str ) for x in [ loss_prefix , loss_suffix , out_prefix , out_suffix ] ): raise TypeError ( \"loss prefix/suffix and out prefix/suffix must be strings\" ) self . loss_prefix = loss_prefix self . loss_suffix = loss_suffix self . out_prefix = out_prefix self . out_suffix = out_suffix self . key_map = c_f . default ( key_map , {}) self . in_keys = [] _loss_keys ( self ) private \u00b6 This must be implemented by the child class Returns: Type Description List[str] The names of the losses that will be added to the context. Source code in pytorch_adapt\\hooks\\base.py 83 84 85 86 87 88 89 90 @abstractmethod def _loss_keys ( self ) -> List [ str ]: \"\"\" This must be implemented by the child class Returns: The names of the losses that will be added to the context. \"\"\" pass _out_keys ( self ) private \u00b6 This must be implemented by the child class Returns: Type Description List[str] The names of the outputs that will be added to the context. Source code in pytorch_adapt\\hooks\\base.py 98 99 100 101 102 103 104 105 @abstractmethod def _out_keys ( self ) -> List [ str ]: \"\"\" This must be implemented by the child class Returns: The names of the outputs that will be added to the context. \"\"\" pass call ( self , losses , inputs ) \u00b6 This must be implemented by the child class Parameters: Name Type Description Default losses Dict[str, Any] previously computed losses required inputs Dict[str, Any] holds everything else: tensors, models etc. required Returns: Type Description Union[Tuple[Dict[str, Any], Dict[str, Any]], bool] Either a tuple of (losses, outputs) that will be merged with the input context, or a boolean Source code in pytorch_adapt\\hooks\\base.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @abstractmethod def call ( self , losses : Dict [ str , Any ], inputs : Dict [ str , Any ] ) -> Union [ Tuple [ Dict [ str , Any ], Dict [ str , Any ]], bool ]: \"\"\" This must be implemented by the child class Arguments: losses: previously computed losses inputs: holds everything else: tensors, models etc. Returns: Either a tuple of (losses, outputs) that will be merged with the input context, or a boolean \"\"\" pass BaseWrapperHook \u00b6 A simple wrapper for calling self.hook , which should be defined in the child's __init__ function.","title":"Base"},{"location":"hooks/base/#pytorch_adapt.hooks.base","text":"","title":"base"},{"location":"hooks/base/#pytorch_adapt.hooks.base.BaseConditionHook","text":"The base class for hooks that return a boolean","title":"BaseConditionHook"},{"location":"hooks/base/#pytorch_adapt.hooks.base.BaseHook","text":"All hooks extend BaseHook","title":"BaseHook"},{"location":"hooks/base/#pytorch_adapt.hooks.base.BaseHook.__init__","text":"Parameters: Name Type Description Default loss_prefix str prepended to all new loss keys '' loss_suffix str appended to all new loss keys '' out_prefix str prepended to all new output keys '' out_suffix str appended to all new output keys '' key_map Dict[str, str] a mapping from input_key to new_key . For example, if key_map = {\"A\": \"B\"}, and the input dict to __call__ is {\"A\": 5}, then the input will be converted to {\"B\": 5} before being consumed. Before exiting __call__ , the mapping is undone so the input context is preserved. In other words, {\"B\": 5} will be converted back to {\"A\": 5}. None Source code in pytorch_adapt\\hooks\\base.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def __init__ ( self , loss_prefix : str = \"\" , loss_suffix : str = \"\" , out_prefix : str = \"\" , out_suffix : str = \"\" , key_map : Dict [ str , str ] = None , ): \"\"\" Arguments: loss_prefix: prepended to all new loss keys loss_suffix: appended to all new loss keys out_prefix: prepended to all new output keys out_suffix: appended to all new output keys key_map: a mapping from ```input_key``` to ```new_key```. For example, if key_map = {\"A\": \"B\"}, and the input dict to ```__call__``` is {\"A\": 5}, then the input will be converted to {\"B\": 5} before being consumed. Before exiting ```__call__```, the mapping is undone so the input context is preserved. In other words, {\"B\": 5} will be converted back to {\"A\": 5}. \"\"\" if any ( not isinstance ( x , str ) for x in [ loss_prefix , loss_suffix , out_prefix , out_suffix ] ): raise TypeError ( \"loss prefix/suffix and out prefix/suffix must be strings\" ) self . loss_prefix = loss_prefix self . loss_suffix = loss_suffix self . out_prefix = out_prefix self . out_suffix = out_suffix self . key_map = c_f . default ( key_map , {}) self . in_keys = []","title":"__init__()"},{"location":"hooks/base/#pytorch_adapt.hooks.base.BaseHook._loss_keys","text":"This must be implemented by the child class Returns: Type Description List[str] The names of the losses that will be added to the context. Source code in pytorch_adapt\\hooks\\base.py 83 84 85 86 87 88 89 90 @abstractmethod def _loss_keys ( self ) -> List [ str ]: \"\"\" This must be implemented by the child class Returns: The names of the losses that will be added to the context. \"\"\" pass","title":"_loss_keys()"},{"location":"hooks/base/#pytorch_adapt.hooks.base.BaseHook._out_keys","text":"This must be implemented by the child class Returns: Type Description List[str] The names of the outputs that will be added to the context. Source code in pytorch_adapt\\hooks\\base.py 98 99 100 101 102 103 104 105 @abstractmethod def _out_keys ( self ) -> List [ str ]: \"\"\" This must be implemented by the child class Returns: The names of the outputs that will be added to the context. \"\"\" pass","title":"_out_keys()"},{"location":"hooks/base/#pytorch_adapt.hooks.base.BaseHook.call","text":"This must be implemented by the child class Parameters: Name Type Description Default losses Dict[str, Any] previously computed losses required inputs Dict[str, Any] holds everything else: tensors, models etc. required Returns: Type Description Union[Tuple[Dict[str, Any], Dict[str, Any]], bool] Either a tuple of (losses, outputs) that will be merged with the input context, or a boolean Source code in pytorch_adapt\\hooks\\base.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 @abstractmethod def call ( self , losses : Dict [ str , Any ], inputs : Dict [ str , Any ] ) -> Union [ Tuple [ Dict [ str , Any ], Dict [ str , Any ]], bool ]: \"\"\" This must be implemented by the child class Arguments: losses: previously computed losses inputs: holds everything else: tensors, models etc. Returns: Either a tuple of (losses, outputs) that will be merged with the input context, or a boolean \"\"\" pass","title":"call()"},{"location":"hooks/base/#pytorch_adapt.hooks.base.BaseWrapperHook","text":"A simple wrapper for calling self.hook , which should be defined in the child's __init__ function.","title":"BaseWrapperHook"},{"location":"hooks/utils/","text":"pytorch_adapt.hooks.utils \u00b6 ChainHook \u00b6 Calls multiple hooks sequentially. The Nth hook receives the context accumulated through hooks 0 to N-1. __init__ ( self , * hooks , * , conditions = None , alts = None , overwrite = False , ** kwargs ) special \u00b6 Parameters: Name Type Description Default hooks BaseHook a sequence of hooks that will be called sequentially. () conditions List[pytorch_adapt.hooks.base.BaseConditionHook] an optional list of condition hooks. If conditions[i] returns False, then alts[i] is called. Otherwise hooks[i] is called. None alts List[pytorch_adapt.hooks.base.BaseHook] an optional list of hooks that will be executed when the corresponding condition hook returns False None overwrite Union[bool, List[int]] If True, then hooks will be allowed to overwrite keys in the context. If a list of integers, then the hooks at the specified indices will be allowed to overwrite keys in the context. False Source code in pytorch_adapt\\hooks\\utils.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def __init__ ( self , * hooks : BaseHook , conditions : List [ BaseConditionHook ] = None , alts : List [ BaseHook ] = None , overwrite : Union [ bool , List [ int ]] = False , ** kwargs , ): \"\"\" Arguments: hooks: a sequence of hooks that will be called sequentially. conditions: an optional list of condition hooks. If conditions[i] returns False, then alts[i] is called. Otherwise hooks[i] is called. alts: an optional list of hooks that will be executed when the corresponding condition hook returns False overwrite: If True, then hooks will be allowed to overwrite keys in the context. If a list of integers, then the hooks at the specified indices will be allowed to overwrite keys in the context. \"\"\" super () . __init__ ( ** kwargs ) self . hooks = hooks self . conditions = c_f . default ( conditions , [ TrueHook () for _ in range ( len ( hooks ))] ) self . alts = c_f . default ( alts , [ ZeroLossHook ( h . loss_keys , h . out_keys ) for h in self . hooks ] ) self . check_alt_keys_match_hook_keys () if not isinstance ( overwrite , ( list , bool )): raise TypeError ( \"overwrite must be a list or bool\" ) self . overwrite = overwrite self . in_keys = self . hooks [ 0 ] . in_keys EmptyHook \u00b6 Returns two empty dictionaries. FalseHook \u00b6 Returns False NotHook \u00b6 Returns the boolean negation of the wrapped hook. __init__ ( self , hook , ** kwargs ) special \u00b6 Parameters: Name Type Description Default hook BaseConditionHook The condition hook that will be negated. required Source code in pytorch_adapt\\hooks\\utils.py 256 257 258 259 260 261 262 def __init__ ( self , hook : BaseConditionHook , ** kwargs ): \"\"\" Arguments: hook: The condition hook that will be negated. \"\"\" super () . __init__ ( ** kwargs ) self . hook = hook ParallelHook \u00b6 Calls multiple hooks while keeping contexts separate. The Nth hook receives the same context as hooks 0 to N-1. All the output contexts are merged at the end. __init__ ( self , * hooks , ** kwargs ) special \u00b6 Parameters: Name Type Description Default hooks BaseHook a sequence of hooks that will be called sequentially, with each hook receiving the same initial context. () Source code in pytorch_adapt\\hooks\\utils.py 160 161 162 163 164 165 166 167 168 def __init__ ( self , * hooks : BaseHook , ** kwargs ): \"\"\" Arguments: hooks: a sequence of hooks that will be called sequentially, with each hook receiving the same initial context. \"\"\" super () . __init__ ( ** kwargs ) self . hooks = hooks self . in_keys = c_f . join_lists ([ h . in_keys for h in self . hooks ]) TrueHook \u00b6 Returns True","title":"Utils"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils","text":"","title":"utils"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.ChainHook","text":"Calls multiple hooks sequentially. The Nth hook receives the context accumulated through hooks 0 to N-1.","title":"ChainHook"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.ChainHook.__init__","text":"Parameters: Name Type Description Default hooks BaseHook a sequence of hooks that will be called sequentially. () conditions List[pytorch_adapt.hooks.base.BaseConditionHook] an optional list of condition hooks. If conditions[i] returns False, then alts[i] is called. Otherwise hooks[i] is called. None alts List[pytorch_adapt.hooks.base.BaseHook] an optional list of hooks that will be executed when the corresponding condition hook returns False None overwrite Union[bool, List[int]] If True, then hooks will be allowed to overwrite keys in the context. If a list of integers, then the hooks at the specified indices will be allowed to overwrite keys in the context. False Source code in pytorch_adapt\\hooks\\utils.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def __init__ ( self , * hooks : BaseHook , conditions : List [ BaseConditionHook ] = None , alts : List [ BaseHook ] = None , overwrite : Union [ bool , List [ int ]] = False , ** kwargs , ): \"\"\" Arguments: hooks: a sequence of hooks that will be called sequentially. conditions: an optional list of condition hooks. If conditions[i] returns False, then alts[i] is called. Otherwise hooks[i] is called. alts: an optional list of hooks that will be executed when the corresponding condition hook returns False overwrite: If True, then hooks will be allowed to overwrite keys in the context. If a list of integers, then the hooks at the specified indices will be allowed to overwrite keys in the context. \"\"\" super () . __init__ ( ** kwargs ) self . hooks = hooks self . conditions = c_f . default ( conditions , [ TrueHook () for _ in range ( len ( hooks ))] ) self . alts = c_f . default ( alts , [ ZeroLossHook ( h . loss_keys , h . out_keys ) for h in self . hooks ] ) self . check_alt_keys_match_hook_keys () if not isinstance ( overwrite , ( list , bool )): raise TypeError ( \"overwrite must be a list or bool\" ) self . overwrite = overwrite self . in_keys = self . hooks [ 0 ] . in_keys","title":"__init__()"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.EmptyHook","text":"Returns two empty dictionaries.","title":"EmptyHook"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.FalseHook","text":"Returns False","title":"FalseHook"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.NotHook","text":"Returns the boolean negation of the wrapped hook.","title":"NotHook"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.NotHook.__init__","text":"Parameters: Name Type Description Default hook BaseConditionHook The condition hook that will be negated. required Source code in pytorch_adapt\\hooks\\utils.py 256 257 258 259 260 261 262 def __init__ ( self , hook : BaseConditionHook , ** kwargs ): \"\"\" Arguments: hook: The condition hook that will be negated. \"\"\" super () . __init__ ( ** kwargs ) self . hook = hook","title":"__init__()"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.ParallelHook","text":"Calls multiple hooks while keeping contexts separate. The Nth hook receives the same context as hooks 0 to N-1. All the output contexts are merged at the end.","title":"ParallelHook"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.ParallelHook.__init__","text":"Parameters: Name Type Description Default hooks BaseHook a sequence of hooks that will be called sequentially, with each hook receiving the same initial context. () Source code in pytorch_adapt\\hooks\\utils.py 160 161 162 163 164 165 166 167 168 def __init__ ( self , * hooks : BaseHook , ** kwargs ): \"\"\" Arguments: hooks: a sequence of hooks that will be called sequentially, with each hook receiving the same initial context. \"\"\" super () . __init__ ( ** kwargs ) self . hooks = hooks self . in_keys = c_f . join_lists ([ h . in_keys for h in self . hooks ])","title":"__init__()"},{"location":"hooks/utils/#pytorch_adapt.hooks.utils.TrueHook","text":"Returns True","title":"TrueHook"}]}