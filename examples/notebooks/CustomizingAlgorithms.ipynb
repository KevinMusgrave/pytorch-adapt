{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26cc1b",
   "metadata": {},
   "source": [
    "### Create some fake data and models\n",
    "\n",
    "Model names:\n",
    "- G: feature generator\n",
    "- C: classifier\n",
    "- D: discriminator (for adversarial methods)\n",
    "\n",
    "Data names:\n",
    "- src_imgs/target_imgs: source or target data. The ```_imgs``` suffix is misleading, as the data doesn't have to be 2d, so this will probably be changed in a future version of the library.\n",
    "- src_labels: class labels for the source data.\n",
    "- src_domain/target_domain: integers representing the source and target domain. The convention is 0 for source, and 1 for target.\n",
    "- src_sample_idx/target_sample_idx: each sample's index in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_adapt.containers import Models, Optimizers\n",
    "from pytorch_adapt.hooks import validate_hook\n",
    "\n",
    "feature_size = 100\n",
    "G = torch.nn.Linear(1000, feature_size)\n",
    "C = torch.nn.Linear(feature_size, 10)\n",
    "D = torch.nn.Sequential(torch.nn.Linear(feature_size, 1), torch.nn.Flatten(start_dim=0))\n",
    "\n",
    "models = Models({\"G\": G, \"C\": C, \"D\": D})\n",
    "optimizers = Optimizers((torch.optim.Adam, {\"lr\": 0.00001}))\n",
    "optimizers.create_with(models)\n",
    "opts = list(optimizers.values())\n",
    "\n",
    "\n",
    "dataset_size = 10000\n",
    "# one batch worth of \"data\"\n",
    "data = {\n",
    "    \"src_imgs\": torch.randn(32, 1000),\n",
    "    \"target_imgs\": torch.randn(32, 1000),\n",
    "    \"src_labels\": torch.randint(0, 10, size=(32,)),\n",
    "    \"src_domain\": torch.zeros(32),\n",
    "    \"target_domain\": torch.ones(32),\n",
    "    \"src_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
    "    \"target_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55877506",
   "metadata": {},
   "source": [
    "### Register PyTorch forward hooks for demonstration\n",
    "\n",
    "This will keep track of how many times each model is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_count(self, *_):\n",
    "    self.count += 1\n",
    "\n",
    "\n",
    "G.register_forward_hook(forward_count)\n",
    "C.register_forward_hook(forward_count)\n",
    "D.register_forward_hook(forward_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5839570a",
   "metadata": {},
   "source": [
    "### Helper function for this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(model_counts, losses, outputs, G, C, D=None):\n",
    "    def get_shape(v):\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            return v.shape\n",
    "        elif isinstance(v, list):\n",
    "            return [z.shape for z in v]\n",
    "\n",
    "    print(f\"Expected model counts = {dict(model_counts)}\")\n",
    "    true_str = f\"True model counts = G: {G.count}, C: {C.count}\"\n",
    "    if D:\n",
    "        true_str += f\", D: {D.count}\"\n",
    "    print(true_str)\n",
    "    pprint(losses)\n",
    "    pprint({k: get_shape(v) for k, v in outputs.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb92ee",
   "metadata": {},
   "source": [
    "### Source Classifier\n",
    "\n",
    "This hook applies a cross entropy loss on the source data, so it requires source logits to be computed. \n",
    "\n",
    "Therefore, each model (G and C) will be used once:\n",
    "```src_features_logits = C(G(src_imgs))```.\n",
    "\n",
    "We can use ```validate_hook``` to verify that the hook will work with the given data. This function also returns the expected number of times each model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09080c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import ClassifierHook\n",
    "\n",
    "# Reset counts\n",
    "G.count, C.count = 0, 0\n",
    "hook = ClassifierHook(opts)\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})\n",
    "print_info(model_counts, losses, outputs, G, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cade585",
   "metadata": {},
   "source": [
    "### Source Classifier + BSP + BNM\n",
    "\n",
    "Now we'll use the same ```ClassifierHook``` but add some hooks that are useful for domain adaptation.\n",
    "\n",
    "The ```BSPHook``` requires source and target features: \n",
    "\n",
    "- ```src_features = G(src_imgs)```\n",
    "\n",
    "- ```target_features = G(target_imgs)```\n",
    "\n",
    "The ```BNMHook``` requires target logits: ```target_features_logits = C(target_features)```\n",
    "\n",
    "The source logits still need to be computed for the source classification loss. So in total, each model will be used twice.\n",
    "\n",
    "To use these hooks, we pass them as a list into the ```post``` argument. This means that the losses will be computed in the following order: classification, BSP, BNM. The ```ClassifierHook``` takes in optimizers as its first argument, so after the loss is computed, it also computes gradients and updates model weights.\n",
    "\n",
    "The BSP loss tends to be very large, so we add a ```MeanWeighter```. This multiplies each loss by a scalar (1 by default), and then returns the mean of the scaled losses. In this case, we change the weight for ```bsp_loss``` to ```1e-5```.\n",
    "\n",
    "The hook outputs two dictionaries:\n",
    "\n",
    "- losses: a two-level dictionary where the outer level is associated with a particular optimization step (relevant for GAN architectures), and the inner level contains the loss components.\n",
    "- outputs: all the data that was generated by models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import BNMHook, BSPHook\n",
    "from pytorch_adapt.weighters import MeanWeighter\n",
    "\n",
    "# Reset counts\n",
    "G.count, C.count = 0, 0\n",
    "weighter = MeanWeighter(weights={\"bsp_loss\": 1e-5})\n",
    "hook = ClassifierHook(opts, post=[BSPHook(), BNMHook()], weighter=weighter)\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})\n",
    "print_info(model_counts, losses, outputs, G, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16dbf50",
   "metadata": {},
   "source": [
    "### DANN\n",
    "\n",
    "Let's try DANN next. DANN uses a discriminator that tries to distinguish between source and target features. The required data for computing the adversarial loss is:\n",
    "\n",
    "- ```src_features = G(src_imgs)```\n",
    "- ```target_features = G(target_imgs)```\n",
    "- ```src_features_dlogits = D(src_features)```\n",
    "- ```target_features_dlogits = D(target_features)```\n",
    "\n",
    "The ```_dlogits``` suffix represents the output of the discriminator model. In addition to these outputs, DANN uses a classification loss on source data:\n",
    "\n",
    "- ```src_features_logits = C(src_features)```\n",
    "\n",
    "Based on these requirements, the model counts should be G:2, D:2, C:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import DANNHook\n",
    "\n",
    "G.count, C.count, D.count = 0, 0, 0\n",
    "hook = DANNHook(opts)\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})\n",
    "print_info(model_counts, losses, outputs, G, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa74fd",
   "metadata": {},
   "source": [
    "### DANN + MCC + ATDOC\n",
    "\n",
    "Now we'll add two hooks to DANN:\n",
    "\n",
    "- ```MCCHook``` requires target logits. This isn't normally required by DANN, so the count for C should increase by 1.\n",
    "- ```ATDOCHook``` requires source features and logits. These are already required by DANN, so the count for G and C should remain the same.\n",
    "\n",
    "We pass these hooks into the ```post_g``` argument, because we want them to use raw source and target features. (If you passed them in as ```post_d``` then they would use the output of the gradient reversal layer, which we don't want in this case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77daa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import ATDOCHook, MCCHook\n",
    "\n",
    "G.count, C.count, D.count = 0, 0, 0\n",
    "mcc = MCCHook()\n",
    "atdoc = ATDOCHook(dataset_size=dataset_size, feature_dim=100, num_classes=10)\n",
    "\n",
    "hook = DANNHook(opts, post_g=[mcc, atdoc])\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})\n",
    "print_info(model_counts, losses, outputs, G, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c944e724",
   "metadata": {},
   "source": [
    "### CDAN\n",
    "\n",
    "The ```CDANHook``` is adversarial like ```DANNHook```, but it doesn't use a gradient reversal layer. Thus, optimization occurs in two steps: one for updating the generator, and one for updating the discriminator. In each step, the discriminator has to recompute its logits, so it will be used 4 times instead of 2.\n",
    "\n",
    "```CDANHook``` also requires a separate ```feature_combiner``` model that we pass in along with all the other models and data.\n",
    "\n",
    "You'll notice the outputs have different names from DANN's outputs:\n",
    "\n",
    "- All of the ```feature_combiner``` outputs contain the ```_combined``` suffix, as well as the names of the tensors that were combined. \n",
    "- Tensors with the ```_detached``` suffix are detached from the autograd graph. This is done during the discriminator update, to avoid computing gradients for the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405957d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import CDANHook\n",
    "from pytorch_adapt.layers import RandomizedDotProduct\n",
    "from pytorch_adapt.utils import common_functions as c_f\n",
    "\n",
    "G.count, C.count, D.count = 0, 0, 0\n",
    "d_opts = opts[2:]\n",
    "g_opts = opts[:2]\n",
    "misc = {\"feature_combiner\": RandomizedDotProduct([feature_size, 10], feature_size)}\n",
    "\n",
    "hook = CDANHook(d_opts=d_opts, g_opts=g_opts)\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **misc, **data})\n",
    "print_info(model_counts, losses, outputs, G, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f14fe2",
   "metadata": {},
   "source": [
    "### CDAN + VAT\n",
    "\n",
    "Here we present a current failure case of ```validate_hook```. The ```VATHook``` uses ```VATLoss```, and inside of ```VATLoss```, the ```combined_model``` is used twice. ```VATHook``` uses ```VATLoss``` twice, so the ```combined_model``` is used a total of 4 times. However, there is no way for ```validate_hook``` to know this, so its estimates for G and C are off by 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025090e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import VATHook\n",
    "\n",
    "G.count, C.count, D.count = 0, 0, 0\n",
    "misc[\"combined_model\"] = torch.nn.Sequential(G, C)\n",
    "hook = CDANHook(d_opts=d_opts, g_opts=g_opts, post_g=[VATHook()])\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **misc, **data})\n",
    "print_info(model_counts, losses, outputs, G, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2b116",
   "metadata": {},
   "source": [
    "### MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79148420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import MCDHook\n",
    "from pytorch_adapt.layers import MultipleModels\n",
    "\n",
    "C2 = c_f.reinit(C)\n",
    "C_multiple = MultipleModels(C, C2)\n",
    "models[\"C\"] = C_multiple\n",
    "\n",
    "C_multiple.register_forward_hook(forward_count)\n",
    "G.count, C_multiple.count = 0, 0\n",
    "g_opts = opts[0:1]\n",
    "c_opts = opts[1:2]\n",
    "\n",
    "hook = MCDHook(g_opts=g_opts, c_opts=c_opts)\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})\n",
    "print_info(model_counts, losses, outputs, G, C_multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca090d",
   "metadata": {},
   "source": [
    "### MCD + AFN + MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d27961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import AFNHook, AlignerHook\n",
    "\n",
    "hook = MCDHook(g_opts=g_opts, c_opts=c_opts, post_x=[AFNHook()], post_z=[AlignerHook()])\n",
    "validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f888fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
