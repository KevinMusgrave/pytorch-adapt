{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26cc1b",
   "metadata": {},
   "source": [
    "### Create some fake data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_adapt.containers import Models, Optimizers\n",
    "from pytorch_adapt.hooks import validate_hook\n",
    "\n",
    "feature_size = 100\n",
    "G = torch.nn.Linear(1000, feature_size)\n",
    "C = torch.nn.Linear(feature_size, 10)\n",
    "D = torch.nn.Sequential(torch.nn.Linear(feature_size, 1), torch.nn.Flatten(start_dim=0))\n",
    "\n",
    "models = Models({\"G\": G, \"C\": C, \"D\": D})\n",
    "optimizers = Optimizers((torch.optim.Adam, {\"lr\": 0.456}))\n",
    "optimizers.create_with(models)\n",
    "opts = list(optimizers.values())\n",
    "\n",
    "dataset_size = 10000\n",
    "# one batch worth of \"data\"\n",
    "data = {\n",
    "    \"src_imgs\": torch.randn(32, 1000),\n",
    "    \"target_imgs\": torch.randn(32, 1000),\n",
    "    \"src_labels\": torch.randint(0, 10, size=(32,)),\n",
    "    \"src_domain\": torch.zeros(32),\n",
    "    \"target_domain\": torch.zeros(32),\n",
    "    \"src_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
    "    \"target_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55877506",
   "metadata": {},
   "source": [
    "### Register PyTorch forward hooks for demonstration\n",
    "\n",
    "This will keep track of how many times each model is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_count(self, *_):\n",
    "    self.count += 1\n",
    "\n",
    "\n",
    "C.register_forward_hook(forward_count)\n",
    "G.register_forward_hook(forward_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb92ee",
   "metadata": {},
   "source": [
    "### Source Classifier\n",
    "\n",
    "This hook applies a cross entropy loss on the source data, so it requires source logits to be computed. \n",
    "\n",
    "Therefore, each model (G and C) will be used once:\n",
    "```src_logits = C(G(src_imgs))```.\n",
    "\n",
    "We can use ```validate_hook``` to verify that the hook will work with the given data. This function also returns the expected number of times each model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09080c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import ClassifierHook\n",
    "\n",
    "# Reset counts\n",
    "G.count, C.count = 0, 0\n",
    "hook = ClassifierHook(opts)\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})\n",
    "print(f\"Expected model counts = {dict(model_counts)}\")\n",
    "print(f\"True model counts = G: {G.count}, C: {C.count}\")\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cade585",
   "metadata": {},
   "source": [
    "### Source Classifier + BSP + BNM\n",
    "\n",
    "Now we'll use the same ```ClassifierHook``` but add some hooks that are useful for domain adaptation.\n",
    "\n",
    "The ```BSPHook``` requires source and target features: \n",
    "\n",
    "- ```src_features = G(src_imgs)```\n",
    "\n",
    "- ```target_features = G(target_imgs)```\n",
    "\n",
    "The ```BNMHook``` requires target logits: ```target_logits = C(target_features)```\n",
    "\n",
    "The source logits still need to be computed for the source classification loss. So in total, each model will be used twice.\n",
    "\n",
    "To use these hooks, we pass them as a list into the ```post``` argument. This means that the losses will be computed in the following order: classification, BSP, BNM. The ```ClassifierHook``` takes in optimizers as its first argument, so after the loss is computed, it also computes gradients and updates model weights.\n",
    "\n",
    "The BSP loss tends to be very large, so we add a ```MeanWeighter```. This multiplies each loss by a scalar (1 by default), and then returns the mean of the scaled losses. In this case, we change the weight for ```bsp_loss``` to ```1e-5```.\n",
    "\n",
    "The hook outputs two dictionaries:\n",
    "\n",
    "- losses: a two-level dictionary where the outer level is associated with a particular optimization step (relevant for GAN architectures), and the inner level contains the loss components.\n",
    "- outputs: all the data that was generated by models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import BNMHook, BSPHook\n",
    "from pytorch_adapt.weighters import MeanWeighter\n",
    "\n",
    "# Reset counts\n",
    "G.count, C.count = 0, 0\n",
    "weighter = MeanWeighter(weights={\"bsp_loss\": 1e-5})\n",
    "hook = ClassifierHook(opts, post=[BSPHook(), BNMHook()], weighter=weighter)\n",
    "model_counts = validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})\n",
    "print(f\"Expected model counts = {dict(model_counts)}\")\n",
    "print(f\"True model counts = G: {G.count}, C: {C.count}\")\n",
    "pprint(losses)\n",
    "pprint({k: v.shape for k, v in outputs.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16dbf50",
   "metadata": {},
   "source": [
    "### DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import DANNHook\n",
    "\n",
    "hook = DANNHook(opts)\n",
    "validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa74fd",
   "metadata": {},
   "source": [
    "### DANN + MCC + ATDOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77daa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import ATDOCHook, MCCHook\n",
    "\n",
    "mcc = MCCHook()\n",
    "atdoc = ATDOCHook(dataset_size=dataset_size, feature_dim=100, num_classes=10)\n",
    "\n",
    "hook = DANNHook(opts, post_g=[mcc, atdoc])\n",
    "validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c944e724",
   "metadata": {},
   "source": [
    "### CDAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405957d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import CDANHook\n",
    "from pytorch_adapt.layers import RandomizedDotProduct\n",
    "from pytorch_adapt.utils import common_functions as c_f\n",
    "\n",
    "d_opts = opts[2:]\n",
    "g_opts = opts[:2]\n",
    "misc = {\"feature_combiner\": RandomizedDotProduct([feature_size, 10], feature_size)}\n",
    "\n",
    "hook = CDANHook(d_opts=d_opts, g_opts=g_opts)\n",
    "validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **misc, **data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f14fe2",
   "metadata": {},
   "source": [
    "### CDAN + VAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025090e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import VATHook\n",
    "\n",
    "misc[\"combined_model\"] = torch.nn.Sequential(G, C)\n",
    "hook = CDANHook(d_opts=d_opts, g_opts=g_opts, post_g=[VATHook()])\n",
    "validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **misc, **data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2b116",
   "metadata": {},
   "source": [
    "### MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79148420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import MCDHook\n",
    "from pytorch_adapt.layers import MultipleModels\n",
    "\n",
    "C2 = c_f.reinit(C)\n",
    "C = MultipleModels(C, C2)\n",
    "models[\"C\"] = C\n",
    "\n",
    "g_opts = opts[0:1]\n",
    "c_opts = opts[1:2]\n",
    "\n",
    "hook = MCDHook(g_opts=g_opts, c_opts=c_opts)\n",
    "validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca090d",
   "metadata": {},
   "source": [
    "### MCD + AFN + MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d27961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import AFNHook, AlignerHook\n",
    "\n",
    "hook = MCDHook(g_opts=g_opts, c_opts=c_opts, post_x=[AFNHook()], post_z=[AlignerHook()])\n",
    "validate_hook(hook, list(data.keys()))\n",
    "losses, outputs = hook({}, {**models, **data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f888fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
