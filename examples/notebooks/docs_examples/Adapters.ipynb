{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605ea8c",
   "metadata": {},
   "source": [
    "### Helper function and data for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21930ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_adapt.utils.common_functions import get_lr\n",
    "\n",
    "\n",
    "def print_optimizers_slim(adapter):\n",
    "    for k, v in adapter.optimizers.items():\n",
    "        print(f\"{k}: {v.__class__.__name__} with lr={get_lr(v)}\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"src_imgs\": torch.randn(32, 1000),\n",
    "    \"target_imgs\": torch.randn(32, 1000),\n",
    "    \"src_labels\": torch.randint(0, 10, size=(32,)),\n",
    "    \"src_domain\": torch.zeros(32),\n",
    "    \"target_domain\": torch.zeros(32),\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c2c7af",
   "metadata": {},
   "source": [
    "### Adapters Initialization\n",
    "\n",
    "Models are usually the only required argument when initializing adapters. Optimizers are created using the default that is defined in the adapter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9667c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: Adam with lr=0.0001\n",
      "C: Adam with lr=0.0001\n",
      "D: Adam with lr=0.0001\n"
     ]
    }
   ],
   "source": [
    "from pytorch_adapt.adapters import DANN\n",
    "from pytorch_adapt.containers import Models\n",
    "\n",
    "G = torch.nn.Linear(1000, 100)\n",
    "C = torch.nn.Linear(100, 10)\n",
    "D = torch.nn.Sequential(torch.nn.Linear(100, 1), torch.nn.Flatten(start_dim=0))\n",
    "models = Models({\"G\": G, \"C\": C, \"D\": D})\n",
    "\n",
    "adapter = DANN(models=models)\n",
    "print_optimizers_slim(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07774e88",
   "metadata": {},
   "source": [
    "### Modifying optimizers using the Optimizers container\n",
    "\n",
    "We can use the Optimizers container if we don't want to use the defaults.\n",
    "\n",
    "For example: SGD with lr 0.1 for all 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc771fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: SGD with lr=0.1\n",
      "C: SGD with lr=0.1\n",
      "D: SGD with lr=0.1\n"
     ]
    }
   ],
   "source": [
    "from pytorch_adapt.containers import Optimizers\n",
    "\n",
    "optimizers = Optimizers((torch.optim.SGD, {\"lr\": 0.1}))\n",
    "adapter = DANN(models=models, optimizers=optimizers)\n",
    "print_optimizers_slim(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5293a9d",
   "metadata": {},
   "source": [
    "SGD with lr 0.1 for the G and C models only. The default optimizer will be used for D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c8a060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: SGD with lr=0.1\n",
      "C: SGD with lr=0.1\n",
      "D: Adam with lr=0.0001\n"
     ]
    }
   ],
   "source": [
    "optimizers = Optimizers((torch.optim.SGD, {\"lr\": 0.1}), keys=[\"G\", \"C\"])\n",
    "adapter = DANN(models=models, optimizers=optimizers)\n",
    "print_optimizers_slim(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fdabd",
   "metadata": {},
   "source": [
    "SGD with lr 0.1 for G, and SGD with lr 0.5 for C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b0ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: SGD with lr=0.1\n",
      "C: SGD with lr=0.5\n",
      "D: Adam with lr=0.0001\n"
     ]
    }
   ],
   "source": [
    "optimizers = Optimizers(\n",
    "    {\"G\": (torch.optim.SGD, {\"lr\": 0.1}), \"C\": (torch.optim.SGD, {\"lr\": 0.5})}\n",
    ")\n",
    "adapter = DANN(models=models, optimizers=optimizers)\n",
    "print_optimizers_slim(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d57a5",
   "metadata": {},
   "source": [
    "You can also create the optimizers yourself and pass them into the Optimizers container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1a17df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: SGD with lr=0.123\n",
      "C: Adam with lr=0.0001\n",
      "D: Adam with lr=0.0001\n"
     ]
    }
   ],
   "source": [
    "optimizers = Optimizers({\"G\": torch.optim.SGD(G.parameters(), lr=0.123)})\n",
    "adapter = DANN(models=models, optimizers=optimizers)\n",
    "print_optimizers_slim(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d62e48",
   "metadata": {},
   "source": [
    "### Adding LR Schedulers\n",
    "\n",
    "LR schedulers can be added with the LRSchedulers container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddd34b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G: <torch.optim.lr_scheduler.ExponentialLR object at 0x7f5db619a1f0>\n",
      "C: <torch.optim.lr_scheduler.StepLR object at 0x7f5db619a280>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch_adapt.containers import LRSchedulers\n",
    "\n",
    "optimizers = Optimizers((torch.optim.Adam, {\"lr\": 1}))\n",
    "lr_schedulers = LRSchedulers(\n",
    "    {\n",
    "        \"G\": (torch.optim.lr_scheduler.ExponentialLR, {\"gamma\": 0.99}),\n",
    "        \"C\": (torch.optim.lr_scheduler.StepLR, {\"step_size\": 2}),\n",
    "    },\n",
    "    scheduler_types={\"per_step\": [\"G\"], \"per_epoch\": [\"C\"]},\n",
    ")\n",
    "adapter = DANN(models=models, optimizers=optimizers, lr_schedulers=lr_schedulers)\n",
    "print(adapter.lr_schedulers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b0e05",
   "metadata": {},
   "source": [
    "If you don't wrap the adapter with a framework, then you have to step the lr schedulers manually as shown below.\n",
    "\n",
    "(Here we're just demonstrating how the lr scheduler container works, so we're stepping it without computing a loss or stepping the optimizers etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5902afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch=0\n",
      "G: Adam with lr=0.9509900498999999\n",
      "C: Adam with lr=1\n",
      "D: Adam with lr=1\n",
      "End of epoch=1\n",
      "G: Adam with lr=0.9043820750088043\n",
      "C: Adam with lr=0.1\n",
      "D: Adam with lr=1\n",
      "End of epoch=2\n",
      "G: Adam with lr=0.8600583546412883\n",
      "C: Adam with lr=0.1\n",
      "D: Adam with lr=1\n",
      "End of epoch=3\n",
      "G: Adam with lr=0.8179069375972307\n",
      "C: Adam with lr=0.010000000000000002\n",
      "D: Adam with lr=1\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    for i in range(5):\n",
    "        adapter.lr_schedulers.step(\"per_step\")\n",
    "    adapter.lr_schedulers.step(\"per_epoch\")\n",
    "    print(f\"End of epoch={epoch}\")\n",
    "    print_optimizers_slim(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1250fe",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55a20848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_loss': {'src_domain_loss': 3386.35498046875, 'target_domain_loss': 1900.6820068359375, 'c_loss': 0.0, 'total': 1762.345703125}}\n"
     ]
    }
   ],
   "source": [
    "from pytorch_adapt.utils import common_functions as c_f\n",
    "\n",
    "adapter.models.to(device)\n",
    "data = c_f.batch_to_device(data, device)\n",
    "loss = adapter.training_step(data)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f96f0",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a9a7f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "inference_data = torch.randn(32, 1000).to(device)\n",
    "features, logits = adapter.inference(inference_data)\n",
    "print(features.shape)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dfbc07",
   "metadata": {},
   "source": [
    "### Passing in a custom inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0086112b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using custom_inference_fn\n",
      "torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "def custom_inference_fn(cls):\n",
    "    def return_fn(x):\n",
    "        print(\"using custom_inference_fn\")\n",
    "        return cls.models[\"G\"](x)\n",
    "\n",
    "    return return_fn\n",
    "\n",
    "\n",
    "adapter_custom = DANN(models=models, inference=custom_inference_fn)\n",
    "features = adapter_custom.inference(inference_data)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59716b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
