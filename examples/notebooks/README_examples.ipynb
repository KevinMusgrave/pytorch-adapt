{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49fb4b2",
   "metadata": {},
   "source": [
    "### Load a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf5505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_adapt.datasets.getters import get_mnist_mnistm\n",
    "\n",
    "# mnist is the source domain\n",
    "# mnistm is the target domain\n",
    "datasets = get_mnist_mnistm([\"mnist\"], [\"mnistm\"], \".\")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets[\"train\"], batch_size=32, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fad561",
   "metadata": {},
   "source": [
    "### Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b08ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.models import Classifier, Discriminator, MNISTFeatures\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "G = MNISTFeatures().to(device)\n",
    "C = Classifier(num_classes=10, in_size=1200, h=256).to(device)\n",
    "D = Discriminator(in_size=1200, h=256).to(device)\n",
    "models = {\"G\": G, \"C\": C, \"D\": D}\n",
    "\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0001)\n",
    "C_opt = torch.optim.Adam(C.parameters(), lr=0.0001)\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=0.0001)\n",
    "optimizers = [G_opt, C_opt, D_opt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86afd0d",
   "metadata": {},
   "source": [
    "### Use in vanilla PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import DANNHook\n",
    "from pytorch_adapt.utils.common_functions import batch_to_device\n",
    "\n",
    "# Assuming that models, optimizers, and dataloader are already created.\n",
    "hook = DANNHook(optimizers)\n",
    "for data in dataloader:\n",
    "    data = batch_to_device(data, device)\n",
    "    # Optimization is done inside the hook.\n",
    "    # The returned loss is for logging.\n",
    "    loss, _ = hook({}, {**models, **data})\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c1220",
   "metadata": {},
   "source": [
    "### Build complex algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1582602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import EntropyReducer, MeanReducer, VATHook\n",
    "\n",
    "# G and C are the Generator and Classifier models\n",
    "misc = {\"combined_model\": torch.nn.Sequential(G, C)}\n",
    "reducer = EntropyReducer(\n",
    "    apply_to=[\"src_domain_loss\", \"target_domain_loss\"], default_reducer=MeanReducer()\n",
    ")\n",
    "hook = DANNHook(optimizers, reducer=reducer, post_g=[VATHook()])\n",
    "for data in dataloader:\n",
    "    data = batch_to_device(data, device)\n",
    "    loss, _ = hook({}, {**models, **data, **misc})\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d7986",
   "metadata": {},
   "source": [
    "### Remove some boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81230570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_adapt.adapters import DANN\n",
    "from pytorch_adapt.containers import Models, Optimizers\n",
    "\n",
    "# Assume G, C and D are existing models\n",
    "models = Models(models)\n",
    "# Override the default optimizer for G and C\n",
    "optimizers = Optimizers((torch.optim.Adam, {\"lr\": 0.123}), keys=[\"G\", \"C\"])\n",
    "adapter = DANN(models=models, optimizers=optimizers)\n",
    "\n",
    "for data in dataloader:\n",
    "    adapter.training_step(data, device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f8823",
   "metadata": {},
   "source": [
    "### Wrap with your favorite PyTorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.frameworks import Ignite\n",
    "\n",
    "wrapped_adapter = Ignite(adapter)\n",
    "wrapped_adapter.run(datasets, epoch_length=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f10fe",
   "metadata": {},
   "source": [
    "### Check accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.randn(10000, 100)\n",
    "\n",
    "from pytorch_adapt.validators import SNDValidator\n",
    "\n",
    "# Assuming predictions have been collected\n",
    "target_train = {\"preds\": preds}\n",
    "validator = SNDValidator()\n",
    "score = validator.score(epoch=1, target_train=target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.validators import SNDValidator\n",
    "\n",
    "validator = SNDValidator()\n",
    "wrapped_adapter.run(datasets, validator=validator, epoch_length=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
