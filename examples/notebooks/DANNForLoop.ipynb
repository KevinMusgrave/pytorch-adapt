{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd72d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-adapt in c:\\users\\kevin\\anaconda3\\envs\\pydocs\\lib\\site-packages (0.0.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8bd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from pytorch_adapt.datasets import (\n",
    "    MNISTM,\n",
    "    CombinedSourceAndTargetDataset,\n",
    "    SourceDataset,\n",
    "    TargetDataset,\n",
    ")\n",
    "from pytorch_adapt.hooks import DANNHook\n",
    "from pytorch_adapt.models import Classifier, Discriminator, MNISTFeatures\n",
    "from pytorch_adapt.utils.common_functions import batch_to_device\n",
    "from pytorch_adapt.utils.constants import IMAGENET_MEAN, IMAGENET_STD\n",
    "from pytorch_adapt.utils.transforms import GrayscaleToRGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bca7bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\anaconda3\\envs\\pydocs\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_T = T.Compose(\n",
    "    [\n",
    "        T.Resize(32),\n",
    "        T.ToTensor(),\n",
    "        GrayscaleToRGB(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mnistm_T = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "src_train = MNIST(root=\".\", train=True, download=True, transform=mnist_T)\n",
    "src_val = MNIST(root=\".\", train=False, transform=mnist_T)\n",
    "target_train = MNISTM(root=\".\", train=True, transform=mnistm_T)\n",
    "target_val = MNISTM(root=\".\", train=False, transform=mnistm_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ccfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train = SourceDataset(src_train)\n",
    "src_val = SourceDataset(src_val)\n",
    "target_train = TargetDataset(target_train)\n",
    "target_val = TargetDataset(target_val)\n",
    "\n",
    "train_set = CombinedSourceAndTargetDataset(src_train, target_train)\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5313ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "G = MNISTFeatures().to(device)\n",
    "C = Classifier(num_classes=10, in_size=1200, h=256).to(device)\n",
    "D = Discriminator(in_size=1200, h=256).to(device)\n",
    "models = {\"G\": G, \"C\": C, \"D\": D}\n",
    "\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0001)\n",
    "C_opt = torch.optim.Adam(C.parameters(), lr=0.0001)\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=0.0001)\n",
    "opts = [G_opt, C_opt, D_opt]\n",
    "\n",
    "hook = DANNHook(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b27d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\anaconda3\\envs\\pydocs\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_loss': {'src_domain_loss': 0.6909892559051514, 'target_domain_loss': 0.700066089630127, 'c_loss': 2.305485248565674, 'total': 1.2321802377700806}}\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    data = batch_to_device(data, device)\n",
    "    loss, loss_components = hook({}, {**models, **data})\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a72c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
