{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "940f8d35",
      "metadata": {
        "id": "940f8d35",
        "outputId": "0f410cfb-4da0-4fb6-8659-31eb6033acac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-adapt\n",
            "  Downloading pytorch_adapt-0.0.61-py3-none-any.whl (137 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 71 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 102 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 112 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 122 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 137 kB 13.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (0.11.1+cu111)\n",
            "Collecting pytorch-metric-learning>=1.1.0\n",
            "  Downloading pytorch_metric_learning-1.2.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.21.5)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n",
            "\u001b[K     |████████████████████████████████| 397 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-adapt) (3.10.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (3.1.0)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics->pytorch-adapt) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics->pytorch-adapt) (3.0.7)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-adapt) (7.1.2)\n",
            "Installing collected packages: pyDeprecate, torchmetrics, pytorch-metric-learning, pytorch-adapt\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-adapt-0.0.61 pytorch-metric-learning-1.2.0 torchmetrics-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-adapt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fed50ac",
      "metadata": {
        "id": "7fed50ac"
      },
      "source": [
        "### Helper function for demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "279491ff",
      "metadata": {
        "id": "279491ff"
      },
      "outputs": [],
      "source": [
        "from pytorch_adapt.utils.common_functions import get_lr\n",
        "\n",
        "\n",
        "def print_optimizers_slim(optimizers):\n",
        "    for k, v in optimizers.items():\n",
        "        print(\n",
        "            f\"{k}: {v.__class__.__name__} with lr={get_lr(v)} weight_decay={v.param_groups[0]['weight_decay']}\"\n",
        "        )\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9549fc31",
      "metadata": {
        "id": "9549fc31"
      },
      "source": [
        "### Containers Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bf6c5be6",
      "metadata": {
        "id": "bf6c5be6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from pytorch_adapt.containers import LRSchedulers, Models, Optimizers\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "G = torch.nn.Linear(1000, 100)\n",
        "C = torch.nn.Linear(100, 10)\n",
        "D = torch.nn.Linear(100, 1)\n",
        "\n",
        "models = Models({\"G\": G, \"C\": C, \"D\": D})\n",
        "optimizers = Optimizers((torch.optim.Adam, {\"lr\": 0.456, \"weight_decay\": 0.123}))\n",
        "schedulers = LRSchedulers((torch.optim.lr_scheduler.ExponentialLR, {\"gamma\": 0.99}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1f10aa",
      "metadata": {
        "id": "4a1f10aa"
      },
      "source": [
        "### Create with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8a05aa1b",
      "metadata": {
        "id": "8a05aa1b",
        "outputId": "4335dbc3-8615-4249-f06b-e46dc4bdf063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: Linear(in_features=1000, out_features=100, bias=True)\n",
            "C: Linear(in_features=100, out_features=10, bias=True)\n",
            "D: Linear(in_features=100, out_features=1, bias=True)\n",
            "\n",
            "G: Adam with lr=0.456 weight_decay=0.123\n",
            "C: Adam with lr=0.456 weight_decay=0.123\n",
            "D: Adam with lr=0.456 weight_decay=0.123\n",
            "\n",
            "G: <torch.optim.lr_scheduler.ExponentialLR object at 0x7fecdace11d0>\n",
            "C: <torch.optim.lr_scheduler.ExponentialLR object at 0x7febc76b3bd0>\n",
            "D: <torch.optim.lr_scheduler.ExponentialLR object at 0x7febc76b3cd0>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimizers.create_with(models)\n",
        "schedulers.create_with(optimizers)\n",
        "\n",
        "print(models)\n",
        "print_optimizers_slim(optimizers)\n",
        "print(schedulers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c9862b",
      "metadata": {
        "id": "90c9862b"
      },
      "source": [
        "### Merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "68d1d4c8",
      "metadata": {
        "id": "68d1d4c8",
        "outputId": "4788b970-5419-460a-8867-ed2fde936949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: Linear(in_features=1000, out_features=100, bias=True)\n",
            "C: Linear(in_features=100, out_features=10, bias=True)\n",
            "D: Linear(in_features=100, out_features=1, bias=True)\n",
            "X: Linear(in_features=20, out_features=1, bias=True)\n",
            "\n",
            "G: SGD with lr=1 weight_decay=1e-05\n",
            "C: Adam with lr=0.456 weight_decay=0\n",
            "D: Adam with lr=0.456 weight_decay=0\n",
            "X: SGD with lr=1 weight_decay=1e-05\n",
            "\n"
          ]
        }
      ],
      "source": [
        "more_models = Models({\"X\": torch.nn.Linear(20, 1)})\n",
        "models.merge(more_models)\n",
        "\n",
        "optimizers = Optimizers((torch.optim.Adam, {\"lr\": 0.456}))\n",
        "special_opt = Optimizers(\n",
        "    (torch.optim.SGD, {\"lr\": 1, \"weight_decay\": 1e-5}), keys=[\"G\", \"X\"]\n",
        ")\n",
        "optimizers.merge(special_opt)\n",
        "optimizers.create_with(models)\n",
        "\n",
        "print(models)\n",
        "print_optimizers_slim(optimizers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2dd98ab",
      "metadata": {
        "id": "e2dd98ab"
      },
      "source": [
        "### Delete keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8b0d1439",
      "metadata": {
        "scrolled": true,
        "id": "8b0d1439",
        "outputId": "b2956a6e-c955-4140-c6fa-6a67c312a2d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C: SGD with lr=0.01 weight_decay=0\n",
            "X: SGD with lr=0.01 weight_decay=0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.containers import DeleteKey\n",
        "\n",
        "opt1 = Optimizers((torch.optim.SGD, {\"lr\": 0.01, \"momentum\": 0.9}))\n",
        "opt2 = Optimizers((DeleteKey, {}), keys=[\"G\", \"D\"])\n",
        "opt1.merge(opt2)\n",
        "opt1.create_with(models)\n",
        "print_optimizers_slim(opt1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b157e78f",
      "metadata": {
        "id": "b157e78f"
      },
      "source": [
        "### Model Container Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6a0522da",
      "metadata": {
        "id": "6a0522da",
        "outputId": "68fdbbaf-3a5c-49fc-caf9-89aee64c210b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G training True\n",
            "C training True\n",
            "D training True\n",
            "X training True\n",
            "G training False\n",
            "C training False\n",
            "D training False\n",
            "X training False\n",
            "G device cuda:0\n",
            "C device cuda:0\n",
            "D device cuda:0\n",
            "X device cuda:0\n"
          ]
        }
      ],
      "source": [
        "models.train()\n",
        "for k, v in models.items():\n",
        "    print(k, \"training\", v.training)\n",
        "\n",
        "models.eval()\n",
        "for k, v in models.items():\n",
        "    print(k, \"training\", v.training)\n",
        "\n",
        "models.zero_grad()\n",
        "models.to(device)\n",
        "for k, v in models.items():\n",
        "    print(k, \"device\", v.weight.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75fd5246",
      "metadata": {
        "id": "75fd5246"
      },
      "source": [
        "### Optimizer Container Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "01f79ba8",
      "metadata": {
        "id": "01f79ba8"
      },
      "outputs": [],
      "source": [
        "data = torch.randn(32, 1000).to(device)\n",
        "models.to(device)\n",
        "\n",
        "for keys in [None, [\"C\"]]:\n",
        "    logits = C(G(data))\n",
        "    loss = torch.sum(logits)\n",
        "\n",
        "    # zero gradients, compute gradients, update weights\n",
        "    if keys is None:\n",
        "        optimizers.zero_back_step(loss)\n",
        "    # only apply zero_back_step to specific optimizers\n",
        "    else:\n",
        "        optimizers.zero_back_step(loss, keys=keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c6e70e3",
      "metadata": {
        "id": "1c6e70e3"
      },
      "source": [
        "### Optimizer LR Multiplier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a8a2d37c",
      "metadata": {
        "id": "a8a2d37c",
        "outputId": "5b79e016-c61d-42a9-8eff-60739cfa285f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: Adam with lr=5.0 weight_decay=0\n",
            "C: Adam with lr=0.05 weight_decay=0\n",
            "D: Adam with lr=0.1 weight_decay=0\n",
            "X: Adam with lr=0.1 weight_decay=0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimizers = Optimizers(\n",
        "    (torch.optim.Adam, {\"lr\": 0.1}), multipliers={\"G\": 50, \"C\": 0.5}\n",
        ")\n",
        "optimizers.create_with(models)\n",
        "print_optimizers_slim(optimizers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16653637",
      "metadata": {
        "id": "16653637"
      },
      "source": [
        "### LR Scheduler Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "12abb042",
      "metadata": {
        "id": "12abb042",
        "outputId": "2c109155-f199-4a1f-ce52-e2d8b630e5ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        }
      ],
      "source": [
        "schedulers = LRSchedulers(\n",
        "    (torch.optim.lr_scheduler.ExponentialLR, {\"gamma\": 0.99}),\n",
        "    scheduler_types={\"per_step\": [\"G\", \"C\"], \"per_epoch\": [\"D\", \"X\"]},\n",
        ")\n",
        "schedulers.create_with(optimizers)\n",
        "\n",
        "# step lr schedulers by type\n",
        "schedulers.step(\"per_step\")\n",
        "schedulers.step(\"per_epoch\")\n",
        "\n",
        "# get lr schedulers by type\n",
        "per_step = schedulers.filter_by_scheduler_type(\"per_step\")\n",
        "per_epoch = schedulers.filter_by_scheduler_type(\"per_epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "36d40af9",
      "metadata": {
        "id": "36d40af9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Containers.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}