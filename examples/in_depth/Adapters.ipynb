{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "342e9a32",
      "metadata": {
        "id": "342e9a32",
        "outputId": "92eb24e9-f477-4de6-ac23-e20b57dc89c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-adapt\n",
            "  Downloading pytorch_adapt-0.0.61-py3-none-any.whl (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n",
            "\u001b[K     |████████████████████████████████| 397 kB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.10.0+cu111)\n",
            "Collecting pytorch-metric-learning>=1.1.0\n",
            "  Downloading pytorch_metric_learning-1.2.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-adapt) (3.10.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (3.1.0)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics->pytorch-adapt) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics->pytorch-adapt) (3.0.7)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-adapt) (7.1.2)\n",
            "Installing collected packages: pyDeprecate, torchmetrics, pytorch-metric-learning, pytorch-adapt\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-adapt-0.0.61 pytorch-metric-learning-1.2.0 torchmetrics-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-adapt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a605ea8c",
      "metadata": {
        "id": "a605ea8c"
      },
      "source": [
        "### Helper function and data for demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "21930ef1",
      "metadata": {
        "id": "21930ef1"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "\n",
        "from pytorch_adapt.utils import common_functions as c_f\n",
        "from pytorch_adapt.utils.common_functions import get_lr\n",
        "\n",
        "\n",
        "def print_optimizers_slim(adapter):\n",
        "    for k, v in adapter.optimizers.items():\n",
        "        print(f\"{k}: {v.__class__.__name__} with lr={get_lr(v)}\")\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"src_imgs\": torch.randn(32, 1000),\n",
        "    \"target_imgs\": torch.randn(32, 1000),\n",
        "    \"src_labels\": torch.randint(0, 10, size=(32,)),\n",
        "    \"src_domain\": torch.zeros(32),\n",
        "    \"target_domain\": torch.zeros(32),\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62c2c7af",
      "metadata": {
        "id": "62c2c7af"
      },
      "source": [
        "### Adapters Initialization\n",
        "\n",
        "Models are usually the only required argument when initializing adapters. Optimizers are created using the default that is defined in the adapter. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9d9667c4",
      "metadata": {
        "id": "9d9667c4",
        "outputId": "5d63b751-0d62-455d-ce51-42078589bd5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: Adam with lr=0.0001\n",
            "C: Adam with lr=0.0001\n",
            "D: Adam with lr=0.0001\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.adapters import DANN\n",
        "from pytorch_adapt.containers import Models\n",
        "\n",
        "G = torch.nn.Linear(1000, 100)\n",
        "C = torch.nn.Linear(100, 10)\n",
        "D = torch.nn.Sequential(torch.nn.Linear(100, 1), torch.nn.Flatten(start_dim=0))\n",
        "models = Models({\"G\": G, \"C\": C, \"D\": D})\n",
        "\n",
        "adapter = DANN(models=models)\n",
        "print_optimizers_slim(adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07774e88",
      "metadata": {
        "id": "07774e88"
      },
      "source": [
        "### Modifying optimizers using the Optimizers container\n",
        "\n",
        "We can use the Optimizers container if we don't want to use the defaults.\n",
        "\n",
        "For example: SGD with lr 0.1 for all 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9cc771fd",
      "metadata": {
        "id": "9cc771fd",
        "outputId": "06bbfc8d-f465-47f8-8e1c-9b4256d30969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: SGD with lr=0.1\n",
            "C: SGD with lr=0.1\n",
            "D: SGD with lr=0.1\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.containers import Optimizers\n",
        "\n",
        "optimizers = Optimizers((torch.optim.SGD, {\"lr\": 0.1}))\n",
        "adapter = DANN(models=models, optimizers=optimizers)\n",
        "print_optimizers_slim(adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5293a9d",
      "metadata": {
        "id": "b5293a9d"
      },
      "source": [
        "SGD with lr 0.1 for the G and C models only. The default optimizer will be used for D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "13c8a060",
      "metadata": {
        "id": "13c8a060",
        "outputId": "6b4c9404-d98e-4cd3-c46b-7724d49fd296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: SGD with lr=0.1\n",
            "C: SGD with lr=0.1\n",
            "D: Adam with lr=0.0001\n"
          ]
        }
      ],
      "source": [
        "optimizers = Optimizers((torch.optim.SGD, {\"lr\": 0.1}), keys=[\"G\", \"C\"])\n",
        "adapter = DANN(models=models, optimizers=optimizers)\n",
        "print_optimizers_slim(adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "726fdabd",
      "metadata": {
        "id": "726fdabd"
      },
      "source": [
        "SGD with lr 0.1 for G, and SGD with lr 0.5 for C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b0b0ba64",
      "metadata": {
        "id": "b0b0ba64",
        "outputId": "3e14d1be-05fc-497a-95e3-7f01c4c80af9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: SGD with lr=0.1\n",
            "C: SGD with lr=0.5\n",
            "D: Adam with lr=0.0001\n"
          ]
        }
      ],
      "source": [
        "optimizers = Optimizers(\n",
        "    {\"G\": (torch.optim.SGD, {\"lr\": 0.1}), \"C\": (torch.optim.SGD, {\"lr\": 0.5})}\n",
        ")\n",
        "adapter = DANN(models=models, optimizers=optimizers)\n",
        "print_optimizers_slim(adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28d57a5",
      "metadata": {
        "id": "d28d57a5"
      },
      "source": [
        "You can also create the optimizers yourself and pass them into the Optimizers container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ff1a17df",
      "metadata": {
        "id": "ff1a17df",
        "outputId": "57e1d518-dfc7-4025-bcce-d2d001feca7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: SGD with lr=0.123\n",
            "C: Adam with lr=0.0001\n",
            "D: Adam with lr=0.0001\n"
          ]
        }
      ],
      "source": [
        "optimizers = Optimizers({\"G\": torch.optim.SGD(G.parameters(), lr=0.123)})\n",
        "adapter = DANN(models=models, optimizers=optimizers)\n",
        "print_optimizers_slim(adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d62e48",
      "metadata": {
        "id": "31d62e48"
      },
      "source": [
        "### Adding LR Schedulers\n",
        "\n",
        "LR schedulers can be added with the LRSchedulers container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ddd34b7f",
      "metadata": {
        "id": "ddd34b7f",
        "outputId": "2f266a76-3396-4d6b-e6a8-fc405498ccb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G: <torch.optim.lr_scheduler.ExponentialLR object at 0x7f55f2888450>\n",
            "C: <torch.optim.lr_scheduler.StepLR object at 0x7f55f2850310>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.containers import LRSchedulers\n",
        "\n",
        "optimizers = Optimizers((torch.optim.Adam, {\"lr\": 1}))\n",
        "lr_schedulers = LRSchedulers(\n",
        "    {\n",
        "        \"G\": (torch.optim.lr_scheduler.ExponentialLR, {\"gamma\": 0.99}),\n",
        "        \"C\": (torch.optim.lr_scheduler.StepLR, {\"step_size\": 2}),\n",
        "    },\n",
        "    scheduler_types={\"per_step\": [\"G\"], \"per_epoch\": [\"C\"]},\n",
        ")\n",
        "adapter = DANN(models=models, optimizers=optimizers, lr_schedulers=lr_schedulers)\n",
        "print(adapter.lr_schedulers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "502b0e05",
      "metadata": {
        "id": "502b0e05"
      },
      "source": [
        "If you don't wrap the adapter with a framework, then you have to step the lr schedulers manually as shown below.\n",
        "\n",
        "(Here we're just demonstrating how the lr scheduler container works, so we're stepping it without computing a loss or stepping the optimizers etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c5902afd",
      "metadata": {
        "id": "c5902afd",
        "outputId": "53a1e5c7-3d9e-4072-9387-8ad6715c9a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of epoch=0\n",
            "G: Adam with lr=0.9509900498999999\n",
            "C: Adam with lr=1\n",
            "D: Adam with lr=1\n",
            "End of epoch=1\n",
            "G: Adam with lr=0.9043820750088043\n",
            "C: Adam with lr=0.1\n",
            "D: Adam with lr=1\n",
            "End of epoch=2\n",
            "G: Adam with lr=0.8600583546412883\n",
            "C: Adam with lr=0.1\n",
            "D: Adam with lr=1\n",
            "End of epoch=3\n",
            "G: Adam with lr=0.8179069375972307\n",
            "C: Adam with lr=0.010000000000000002\n",
            "D: Adam with lr=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(4):\n",
        "    for i in range(5):\n",
        "        adapter.lr_schedulers.step(\"per_step\")\n",
        "    adapter.lr_schedulers.step(\"per_epoch\")\n",
        "    print(f\"End of epoch={epoch}\")\n",
        "    print_optimizers_slim(adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1250fe",
      "metadata": {
        "id": "4b1250fe"
      },
      "source": [
        "### Training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "55a20848",
      "metadata": {
        "id": "55a20848",
        "outputId": "bac11714-50f0-470a-e518-5f86b688f96e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 2.324974775314331,\n",
            "                'src_domain_loss': 0.6968796849250793,\n",
            "                'target_domain_loss': 0.7119814157485962,\n",
            "                'total': 1.2446119785308838}}\n"
          ]
        }
      ],
      "source": [
        "adapter.models.to(device)\n",
        "data = c_f.batch_to_device(data, device)\n",
        "loss = adapter.training_step(data)\n",
        "pprint(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3daa6a8d",
      "metadata": {
        "id": "3daa6a8d"
      },
      "source": [
        "### Customizing the wrapped hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "00d62263",
      "metadata": {
        "id": "00d62263",
        "outputId": "f5cb96c3-2a61-4abd-b014-2666428921f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'bnm_loss': -0.41856831312179565,\n",
            "                'c_loss': 0.0,\n",
            "                'mcc_loss': 0.26807117462158203,\n",
            "                'src_domain_loss': 308.5667724609375,\n",
            "                'target_domain_loss': 29.598712921142578,\n",
            "                'total': 67.60299682617188}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import BNMHook, MCCHook\n",
        "\n",
        "post_g = [BNMHook(), MCCHook()]\n",
        "adapter = DANN(models=models, hook_kwargs={\"post_g\": post_g})\n",
        "data = c_f.batch_to_device(data, device)\n",
        "loss = adapter.training_step(data)\n",
        "pprint(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b2f96f0",
      "metadata": {
        "id": "7b2f96f0"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4a9a7f3a",
      "metadata": {
        "id": "4a9a7f3a",
        "outputId": "08c8aff9-0e2a-4d79-9322-8fd23f384dfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 100])\n",
            "torch.Size([32, 10])\n"
          ]
        }
      ],
      "source": [
        "inference_data = torch.randn(32, 1000).to(device)\n",
        "output = adapter.inference(inference_data)\n",
        "print(output[\"features\"].shape)\n",
        "print(output[\"logits\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dfbc07",
      "metadata": {
        "id": "f6dfbc07"
      },
      "source": [
        "### Custom inference function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0086112b",
      "metadata": {
        "id": "0086112b",
        "outputId": "2ed2d217-b293-4b43-b174-787476e683c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using custom_inference_fn\n",
            "torch.Size([32, 100])\n"
          ]
        }
      ],
      "source": [
        "def inference_fn(x, models, **kwargs):\n",
        "    print(\"using custom_inference_fn\")\n",
        "    return {\"features\": models[\"G\"](x)}\n",
        "\n",
        "\n",
        "adapter_custom = DANN(models=models, inference_fn=inference_fn)\n",
        "output = adapter_custom.inference(inference_data)\n",
        "print(output[\"features\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3b59716b",
      "metadata": {
        "id": "3b59716b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Adapters.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}