{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-adapt[lightning,ignite]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49fb4b2",
   "metadata": {},
   "source": [
    "### Load a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf5505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_adapt.datasets import get_mnist_mnistm\n",
    "\n",
    "# mnist is the source domain\n",
    "# mnistm is the target domain\n",
    "datasets = get_mnist_mnistm([\"mnist\"], [\"mnistm\"], \".\", download=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets[\"train\"], batch_size=32, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fad561",
   "metadata": {},
   "source": [
    "### Load toy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b08ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.models import Discriminator, mnistC, mnistG\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    G = mnistG(pretrained=True).to(device)\n",
    "    C = mnistC(pretrained=True).to(device)\n",
    "    D = Discriminator(in_size=1200, h=256).to(device)\n",
    "    return {\"G\": G, \"C\": C, \"D\": D}\n",
    "\n",
    "\n",
    "def get_optimizers(models):\n",
    "    G_opt = torch.optim.Adam(models[\"G\"].parameters(), lr=0.0001)\n",
    "    C_opt = torch.optim.Adam(models[\"C\"].parameters(), lr=0.0001)\n",
    "    D_opt = torch.optim.Adam(models[\"D\"].parameters(), lr=0.0001)\n",
    "    return [G_opt, C_opt, D_opt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86afd0d",
   "metadata": {},
   "source": [
    "### Use in vanilla PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import DANNHook\n",
    "from pytorch_adapt.utils.common_functions import batch_to_device\n",
    "\n",
    "models = get_models()\n",
    "optimizers = get_optimizers(models)\n",
    "\n",
    "# Assuming that models, optimizers, and dataloader are already created.\n",
    "hook = DANNHook(optimizers)\n",
    "for data in tqdm(dataloader):\n",
    "    data = batch_to_device(data, device)\n",
    "    # Optimization is done inside the hook.\n",
    "    # The returned loss is for logging.\n",
    "    loss, _ = hook({}, {**models, **data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c1220",
   "metadata": {},
   "source": [
    "### Build complex algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1582602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import MCCHook, VATHook\n",
    "\n",
    "models = get_models()\n",
    "optimizers = get_optimizers(models)\n",
    "\n",
    "# G and C are the Generator and Classifier models\n",
    "G, C = models[\"G\"], models[\"C\"]\n",
    "misc = {\"combined_model\": torch.nn.Sequential(G, C)}\n",
    "hook = DANNHook(optimizers, post_g=[MCCHook(), VATHook()])\n",
    "for data in tqdm(dataloader):\n",
    "    data = batch_to_device(data, device)\n",
    "    loss, _ = hook({}, {**models, **data, **misc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f8823",
   "metadata": {},
   "source": [
    "### Wrap with your favorite PyTorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10720dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.adapters import DANN\n",
    "from pytorch_adapt.containers import Models\n",
    "from pytorch_adapt.datasets import DataloaderCreator\n",
    "\n",
    "models = get_models()\n",
    "models_cont = Models(models)\n",
    "adapter = DANN(models=models_cont)\n",
    "dc = DataloaderCreator(num_workers=2)\n",
    "dataloaders = dc(**datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1faec48",
   "metadata": {},
   "source": [
    "#### Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_adapt.frameworks.lightning import Lightning\n",
    "\n",
    "L_adapter = Lightning(adapter)\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=1)\n",
    "trainer.fit(L_adapter, dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0061eb",
   "metadata": {},
   "source": [
    "#### Ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.frameworks.ignite import Ignite\n",
    "\n",
    "models = get_models()\n",
    "models_cont = Models(models)\n",
    "adapter = DANN(models=models_cont)\n",
    "\n",
    "trainer = Ignite(adapter)\n",
    "trainer.run(datasets, dataloader_creator=dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f10fe",
   "metadata": {},
   "source": [
    "### Check your model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.validators import SNDValidator\n",
    "\n",
    "# Random predictions as placeholder\n",
    "preds = torch.randn(1000, 100)\n",
    "\n",
    "# Assuming predictions have been collected\n",
    "target_train = {\"preds\": preds}\n",
    "validator = SNDValidator()\n",
    "score = validator.score(target_train=target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c71242",
   "metadata": {},
   "source": [
    "#### Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3691423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.frameworks.utils import filter_datasets\n",
    "\n",
    "models = get_models()\n",
    "models_cont = Models(models)\n",
    "adapter = DANN(models=models_cont)\n",
    "validator = SNDValidator()\n",
    "dataloaders = dc(**filter_datasets(datasets, validator))\n",
    "train_loader = dataloaders.pop(\"train\")\n",
    "\n",
    "L_adapter = Lightning(adapter, validator=validator)\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=1)\n",
    "trainer.fit(L_adapter, train_loader, *dataloaders.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ba312",
   "metadata": {},
   "source": [
    "#### Ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.validators import ScoreHistory\n",
    "\n",
    "models = get_models()\n",
    "models_cont = Models(models)\n",
    "adapter = DANN(models=models_cont)\n",
    "\n",
    "validator = ScoreHistory(SNDValidator())\n",
    "trainer = Ignite(adapter, validator=validator)\n",
    "trainer.run(datasets, dataloader_creator=dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f22fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
