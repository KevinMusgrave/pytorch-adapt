{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abb0d8",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "# Models\n",
    "G = torch.nn.Linear(1000, 100)\n",
    "C = torch.nn.Linear(100, 10)\n",
    "D = torch.nn.Sequential(torch.nn.Linear(100, 1), torch.nn.Flatten(start_dim=0))\n",
    "G_opt = torch.optim.Adam(G.parameters())\n",
    "C_opt = torch.optim.Adam(C.parameters())\n",
    "D_opt = torch.optim.Adam(D.parameters())\n",
    "\n",
    "dataset_size = 10000\n",
    "# 1 batch of data\n",
    "example_data = {\n",
    "    \"src_imgs\": torch.randn(32, 1000),\n",
    "    \"target_imgs\": torch.randn(32, 1000),\n",
    "    \"src_labels\": torch.randint(0, 10, size=(32,)),\n",
    "    \"src_domain\": torch.zeros(32),\n",
    "    \"target_domain\": torch.zeros(32),\n",
    "    \"src_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
    "    \"target_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
    "}\n",
    "\n",
    "\n",
    "def get_data(keys):\n",
    "    return {k: example_data[k] for k in keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535c55f",
   "metadata": {},
   "source": [
    "### [Adversarial Discriminative Domain Adaptation](https://arxiv.org/abs/1702.05464) (ADDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import ADDAHook\n",
    "\n",
    "# make Target model\n",
    "T = copy.deepcopy(G)\n",
    "T_opt = torch.optim.Adam(T.parameters())\n",
    "hook = ADDAHook(g_opts=[T_opt], d_opts=[D_opt])\n",
    "\n",
    "models = {\"G\": G, \"C\": C, \"D\": D, \"T\": T}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_domain\", \"target_domain\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def8c3a",
   "metadata": {},
   "source": [
    "### [Larger Norm More Transferable: An Adaptive Feature Norm Approach for Unsupervised Domain Adaptation](https://arxiv.org/abs/1811.07456) (AFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import AFNHook, ClassifierHook\n",
    "\n",
    "hook = ClassifierHook(opts=[G_opt, C_opt], post=[AFNHook()])\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f0ba2",
   "metadata": {},
   "source": [
    "### [Domain Adaptation with Auxiliary Target Domain-Oriented Classifier](https://arxiv.org/abs/2007.04171) (ATDOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import ATDOCHook, ClassifierHook\n",
    "\n",
    "atdoc = ATDOCHook(dataset_size=10000, feature_dim=100, num_classes=10)\n",
    "hook = ClassifierHook(opts=[G_opt, C_opt], post=[atdoc])\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\", \"target_sample_idx\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a20f4",
   "metadata": {},
   "source": [
    "### [Towards Discriminability and Diversity: Batch Nuclear-norm Maximization under Label Insufficient Situations](https://arxiv.org/abs/2003.12237) (BNM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import BNMHook, ClassifierHook\n",
    "\n",
    "hook = ClassifierHook(opts=[G_opt, C_opt], post=[BNMHook()])\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e070f",
   "metadata": {},
   "source": [
    "### [Transferability vs. Discriminability: Batch Spectral Penalization for Adversarial Domain Adaptation](http://proceedings.mlr.press/v97/chen19i.html) (BSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e51fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import BSPHook, ClassifierHook\n",
    "from pytorch_adapt.weighters import MeanWeighter\n",
    "\n",
    "weighter = MeanWeighter(weights={\"bsp_loss\": 1e-3})\n",
    "hook = ClassifierHook(opts=[G_opt, C_opt], post=[BSPHook()], weighter=weighter)\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b1614",
   "metadata": {},
   "source": [
    "### [Conditional Adversarial Domain Adaptation](https://arxiv.org/abs/1705.10667) (CDAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import CDANHook\n",
    "from pytorch_adapt.layers import RandomizedDotProduct\n",
    "\n",
    "feature_combiner = RandomizedDotProduct(in_dims=[100, 10], out_dim=100)\n",
    "hook = CDANHook(g_opts=[G_opt, C_opt], d_opts=[D_opt])\n",
    "\n",
    "models = {\"G\": G, \"C\": C, \"D\": D}\n",
    "misc = {\"feature_combiner\": feature_combiner}\n",
    "data = get_data(\n",
    "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
    ")\n",
    "losses, _ = hook({}, {**models, **misc, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c6042",
   "metadata": {},
   "source": [
    "### [Deep CORAL: Correlation Alignment for Deep Domain Adaptation](https://arxiv.org/abs/1607.01719) (CORAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import AlignerPlusCHook\n",
    "from pytorch_adapt.layers import CORALLoss\n",
    "\n",
    "hook = AlignerPlusCHook(opts=[G_opt, C_opt], loss_fn=CORALLoss(), softmax=False)\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248ccfb",
   "metadata": {},
   "source": [
    "### [Domain-Adversarial Training of Neural Networks](https://arxiv.org/abs/1505.07818) (DANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import DANNHook\n",
    "\n",
    "hook = DANNHook(opts=[G_opt, C_opt, D_opt])\n",
    "\n",
    "models = {\"G\": G, \"C\": C, \"D\": D}\n",
    "data = get_data(\n",
    "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
    ")\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896e9d0",
   "metadata": {},
   "source": [
    "### [Simultaneous Deep Transfer Across Domains and Tasks](https://arxiv.org/abs/1510.02192) (Domain Confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import DomainConfusionHook\n",
    "\n",
    "# D has to output 2 values instead of the usual 1\n",
    "D_ = torch.nn.Linear(100, 2)\n",
    "D_opt_ = torch.optim.Adam(D_.parameters())\n",
    "\n",
    "hook = DomainConfusionHook(g_opts=[G_opt, C_opt], d_opts=[D_opt_])\n",
    "\n",
    "models = {\"G\": G, \"C\": C, \"D\": D_}\n",
    "data = get_data(\n",
    "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
    ")\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7327aa4",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import GANHook\n",
    "\n",
    "hook = GANHook(g_opts=[G_opt, C_opt], d_opts=[D_opt])\n",
    "\n",
    "models = {\"G\": G, \"C\": C, \"D\": D}\n",
    "data = get_data(\n",
    "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
    ")\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a8566",
   "metadata": {},
   "source": [
    "### [Gradually Vanishing Bridge for Adversarial Domain Adaptation](https://arxiv.org/abs/2003.13183) (GVB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import GVBHook\n",
    "from pytorch_adapt.layers import ModelWithBridge\n",
    "\n",
    "# Discriminator comes after classifier,\n",
    "# so the input shape is num_classes instead of feature size\n",
    "D_ = torch.nn.Sequential(torch.nn.Linear(10, 1), torch.nn.Flatten(start_dim=0))\n",
    "\n",
    "# Add bridges\n",
    "C_ = ModelWithBridge(C)\n",
    "D_ = ModelWithBridge(D_)\n",
    "C_opt_ = torch.optim.Adam(C_.parameters())\n",
    "D_opt_ = torch.optim.Adam(D_.parameters())\n",
    "\n",
    "hook = GVBHook(opts=[G_opt, C_opt_, D_opt_])\n",
    "\n",
    "models = {\"G\": G, \"C\": C_, \"D\": D_}\n",
    "data = get_data(\n",
    "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
    ")\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff82650",
   "metadata": {},
   "source": [
    "### Information Maximization (IM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import ClassifierHook, TargetDiversityHook, TargetEntropyHook\n",
    "\n",
    "hook = ClassifierHook(\n",
    "    opts=[G_opt, C_opt], post=[TargetEntropyHook(), TargetDiversityHook()]\n",
    ")\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77709eaa",
   "metadata": {},
   "source": [
    "### [Information-Theoretical Learning of Discriminative Clusters for Unsupervised Domain Adaptation](https://icml.cc/2012/papers/566.pdf) (ITL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import (\n",
    "    ClassifierHook,\n",
    "    ISTLossHook,\n",
    "    TargetDiversityHook,\n",
    "    TargetEntropyHook,\n",
    ")\n",
    "\n",
    "hook = ClassifierHook(\n",
    "    opts=[G_opt, C_opt],\n",
    "    post=[ISTLossHook(), TargetEntropyHook(), TargetDiversityHook()],\n",
    ")\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data(\n",
    "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
    ")\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32666c0e",
   "metadata": {},
   "source": [
    "### [Deep Transfer Learning with Joint Adaptation Networks](https://arxiv.org/abs/1605.06636) (JMMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_adapt.hooks import AlignerPlusCHook, JointAlignerHook\n",
    "from pytorch_adapt.layers import MMDLoss\n",
    "from pytorch_adapt.layers.utils import get_kernel_scales\n",
    "\n",
    "kernel_scales = get_kernel_scales(low=-3, high=3, num_kernels=10)\n",
    "loss_fn = MMDLoss(kernel_scales=kernel_scales)\n",
    "aligner_hook = JointAlignerHook(loss_fn=loss_fn)\n",
    "hook = AlignerPlusCHook(opts=[G_opt, C_opt], aligner_hook=aligner_hook)\n",
    "\n",
    "models = {\"G\": G, \"C\": C}\n",
    "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
    "losses, _ = hook({}, {**models, **data})\n",
    "pprint(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf73d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
