{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5c8bff82",
      "metadata": {
        "id": "5c8bff82",
        "outputId": "0e391afc-8a34-4384-da49-1e6825ff3107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-adapt\n",
            "  Downloading pytorch_adapt-0.0.61-py3-none-any.whl (137 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40 kB 38.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 71 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 102 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 112 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 122 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 137 kB 32.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (0.11.1+cu111)\n",
            "Collecting pytorch-metric-learning>=1.1.0\n",
            "  Downloading pytorch_metric_learning-1.2.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-adapt) (1.21.5)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n",
            "\u001b[K     |████████████████████████████████| 397 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-adapt) (3.10.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning>=1.1.0->pytorch-adapt) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics->pytorch-adapt) (21.3)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics->pytorch-adapt) (3.0.7)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-adapt) (7.1.2)\n",
            "Installing collected packages: pyDeprecate, torchmetrics, pytorch-metric-learning, pytorch-adapt\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-adapt-0.0.61 pytorch-metric-learning-1.2.0 torchmetrics-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-adapt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44abb0d8",
      "metadata": {
        "id": "44abb0d8"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6bb7af54",
      "metadata": {
        "id": "6bb7af54"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "\n",
        "# Models\n",
        "G = torch.nn.Linear(1000, 100)\n",
        "C = torch.nn.Linear(100, 10)\n",
        "D = torch.nn.Sequential(torch.nn.Linear(100, 1), torch.nn.Flatten(start_dim=0))\n",
        "G_opt = torch.optim.Adam(G.parameters())\n",
        "C_opt = torch.optim.Adam(C.parameters())\n",
        "D_opt = torch.optim.Adam(D.parameters())\n",
        "\n",
        "dataset_size = 10000\n",
        "# 1 batch of data\n",
        "example_data = {\n",
        "    \"src_imgs\": torch.randn(32, 1000),\n",
        "    \"target_imgs\": torch.randn(32, 1000),\n",
        "    \"src_labels\": torch.randint(0, 10, size=(32,)),\n",
        "    \"src_domain\": torch.zeros(32),\n",
        "    \"target_domain\": torch.zeros(32),\n",
        "    \"src_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
        "    \"target_sample_idx\": torch.randint(0, dataset_size, size=(32,)),\n",
        "}\n",
        "\n",
        "\n",
        "def get_data(keys):\n",
        "    return {k: example_data[k] for k in keys}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4535c55f",
      "metadata": {
        "id": "4535c55f"
      },
      "source": [
        "### [Adversarial Discriminative Domain Adaptation](https://arxiv.org/abs/1702.05464) (ADDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2b65be47",
      "metadata": {
        "id": "2b65be47",
        "outputId": "9439bacc-0dd5-4f14-88a8-5743e05599f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d_loss': {'d_src_domain_loss': 0.6439731121063232,\n",
            "            'd_target_domain_loss': 0.6785831451416016,\n",
            "            'total': 0.6612781286239624},\n",
            " 'g_loss': {'g_target_domain_loss': 0.0, 'total': 0.0}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import ADDAHook\n",
        "\n",
        "# make Target model\n",
        "T = copy.deepcopy(G)\n",
        "T_opt = torch.optim.Adam(T.parameters())\n",
        "hook = ADDAHook(g_opts=[T_opt], d_opts=[D_opt])\n",
        "\n",
        "models = {\"G\": G, \"C\": C, \"D\": D, \"T\": T}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_domain\", \"target_domain\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4def8c3a",
      "metadata": {
        "id": "4def8c3a"
      },
      "source": [
        "### [Larger Norm More Transferable: An Adaptive Feature Norm Approach for Unsupervised Domain Adaptation](https://arxiv.org/abs/1811.07456) (AFN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "398f0e2c",
      "metadata": {
        "id": "398f0e2c",
        "outputId": "537a8133-1c73-45fb-bcf0-1013e0c7038f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'afn_loss': 2.0,\n",
            "                'c_loss': 2.382333278656006,\n",
            "                'total': 2.191166639328003}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import AFNHook, ClassifierHook\n",
        "\n",
        "hook = ClassifierHook(opts=[G_opt, C_opt], post=[AFNHook()])\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f40f0ba2",
      "metadata": {
        "id": "f40f0ba2"
      },
      "source": [
        "### [Domain Adaptation with Auxiliary Target Domain-Oriented Classifier](https://arxiv.org/abs/2007.04171) (ATDOC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e5c7648e",
      "metadata": {
        "id": "e5c7648e",
        "outputId": "3f3b58be-f1a4-4827-87d4-b79cdae97cb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 2.233757495880127,\n",
            "                'pseudo_label_loss': 0.23822198808193207,\n",
            "                'total': 1.2359896898269653}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import ATDOCHook, ClassifierHook\n",
        "\n",
        "atdoc = ATDOCHook(dataset_size=10000, feature_dim=100, num_classes=10)\n",
        "hook = ClassifierHook(opts=[G_opt, C_opt], post=[atdoc])\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\", \"target_sample_idx\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973a20f4",
      "metadata": {
        "id": "973a20f4"
      },
      "source": [
        "### [Towards Discriminability and Diversity: Batch Nuclear-norm Maximization under Label Insufficient Situations](https://arxiv.org/abs/2003.12237) (BNM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "790c5a6f",
      "metadata": {
        "id": "790c5a6f",
        "outputId": "7e761f0e-2024-4001-fa13-89c3afa4a0db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'bnm_loss': -0.12025494128465652,\n",
            "                'c_loss': 1.9182664155960083,\n",
            "                'total': 0.8990057110786438}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import BNMHook, ClassifierHook\n",
        "\n",
        "hook = ClassifierHook(opts=[G_opt, C_opt], post=[BNMHook()])\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc8e070f",
      "metadata": {
        "id": "fc8e070f"
      },
      "source": [
        "### [Transferability vs. Discriminability: Batch Spectral Penalization for Adversarial Domain Adaptation](http://proceedings.mlr.press/v97/chen19i.html) (BSP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "70e51fcf",
      "metadata": {
        "id": "70e51fcf",
        "outputId": "db15688e-95f2-4bb0-cf6b-5b0b82a871d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'bsp_loss': 0.32410016655921936,\n",
            "                'c_loss': 1.565260648727417,\n",
            "                'total': 0.944680392742157}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import BSPHook, ClassifierHook\n",
        "from pytorch_adapt.weighters import MeanWeighter\n",
        "\n",
        "weighter = MeanWeighter(weights={\"bsp_loss\": 1e-3})\n",
        "hook = ClassifierHook(opts=[G_opt, C_opt], post=[BSPHook()], weighter=weighter)\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b6b1614",
      "metadata": {
        "id": "0b6b1614"
      },
      "source": [
        "### [Conditional Adversarial Domain Adaptation](https://arxiv.org/abs/1705.10667) (CDAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6a7b41b2",
      "metadata": {
        "id": "6a7b41b2",
        "outputId": "e65212fa-7615-4f11-f3f0-39a71f4bb1b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d_loss': {'d_src_domain_loss': 0.660281777381897,\n",
            "            'd_target_domain_loss': 0.6792236566543579,\n",
            "            'total': 0.6697527170181274},\n",
            " 'g_loss': {'c_loss': 1.2200168371200562,\n",
            "            'g_src_domain_loss': 0.6587430238723755,\n",
            "            'g_target_domain_loss': 0.6779651045799255,\n",
            "            'total': 0.8522416949272156}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import CDANHook\n",
        "from pytorch_adapt.layers import RandomizedDotProduct\n",
        "\n",
        "feature_combiner = RandomizedDotProduct(in_dims=[100, 10], out_dim=100)\n",
        "hook = CDANHook(g_opts=[G_opt, C_opt], d_opts=[D_opt])\n",
        "\n",
        "models = {\"G\": G, \"C\": C, \"D\": D}\n",
        "misc = {\"feature_combiner\": feature_combiner}\n",
        "data = get_data(\n",
        "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
        ")\n",
        "_, losses = hook({**models, **misc, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "270c6042",
      "metadata": {
        "id": "270c6042"
      },
      "source": [
        "### [Deep CORAL: Correlation Alignment for Deep Domain Adaptation](https://arxiv.org/abs/1607.01719) (CORAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d176bc32",
      "metadata": {
        "id": "d176bc32",
        "outputId": "92427741-2422-43a7-c987-64c6c3ee8689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.9225510954856873,\n",
            "                'features_confusion_loss': 0.009478135965764523,\n",
            "                'logits_confusion_loss': 0.00622877012938261,\n",
            "                'total': 0.3127526640892029}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import AlignerPlusCHook\n",
        "from pytorch_adapt.layers import CORALLoss\n",
        "\n",
        "hook = AlignerPlusCHook(opts=[G_opt, C_opt], loss_fn=CORALLoss(), softmax=False)\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d248ccfb",
      "metadata": {
        "id": "d248ccfb"
      },
      "source": [
        "### [Domain-Adversarial Training of Neural Networks](https://arxiv.org/abs/1505.07818) (DANN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "32fdb473",
      "metadata": {
        "id": "32fdb473",
        "outputId": "6853b4ae-0725-41f6-d489-32d5f0640e9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.6768689751625061,\n",
            "                'src_domain_loss': 0.6425599455833435,\n",
            "                'target_domain_loss': 0.683060348033905,\n",
            "                'total': 0.6674964427947998}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import DANNHook\n",
        "\n",
        "hook = DANNHook(opts=[G_opt, C_opt, D_opt])\n",
        "\n",
        "models = {\"G\": G, \"C\": C, \"D\": D}\n",
        "data = get_data(\n",
        "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
        ")\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2896e9d0",
      "metadata": {
        "id": "2896e9d0"
      },
      "source": [
        "### [Simultaneous Deep Transfer Across Domains and Tasks](https://arxiv.org/abs/1510.02192) (Domain Confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "97d6fa24",
      "metadata": {
        "id": "97d6fa24",
        "outputId": "5c8b5c7a-867c-4092-b7ab-360995b2c2d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d_loss': {'d_src_domain_loss': 0.8172264695167542,\n",
            "            'd_target_domain_loss': 0.8290322422981262,\n",
            "            'total': 0.8231293559074402},\n",
            " 'g_loss': {'c_loss': 0.48606035113334656,\n",
            "            'g_src_domain_loss': 0.7360879778862,\n",
            "            'g_target_domain_loss': 0.7338228225708008,\n",
            "            'total': 0.6519904136657715}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import DomainConfusionHook\n",
        "\n",
        "# D has to output 2 values instead of the usual 1\n",
        "D_ = torch.nn.Linear(100, 2)\n",
        "D_opt_ = torch.optim.Adam(D_.parameters())\n",
        "\n",
        "hook = DomainConfusionHook(g_opts=[G_opt, C_opt], d_opts=[D_opt_])\n",
        "\n",
        "models = {\"G\": G, \"C\": C, \"D\": D_}\n",
        "data = get_data(\n",
        "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
        ")\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7327aa4",
      "metadata": {
        "id": "b7327aa4"
      },
      "source": [
        "### GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cafe03d8",
      "metadata": {
        "id": "cafe03d8",
        "outputId": "1937cc24-58e3-4a85-c392-d0ff83f9fe8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d_loss': {'d_src_domain_loss': 0.6861247420310974,\n",
            "            'd_target_domain_loss': 0.7300451993942261,\n",
            "            'total': 0.7080849409103394},\n",
            " 'g_loss': {'c_loss': 0.3431521952152252,\n",
            "            'g_src_domain_loss': 0.681054413318634,\n",
            "            'g_target_domain_loss': 0.725422739982605,\n",
            "            'total': 0.5832098126411438}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import GANHook\n",
        "\n",
        "hook = GANHook(g_opts=[G_opt, C_opt], d_opts=[D_opt])\n",
        "\n",
        "models = {\"G\": G, \"C\": C, \"D\": D}\n",
        "data = get_data(\n",
        "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
        ")\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c85a8566",
      "metadata": {
        "id": "c85a8566"
      },
      "source": [
        "### [Gradually Vanishing Bridge for Adversarial Domain Adaptation](https://arxiv.org/abs/2003.13183) (GVB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3cef0674",
      "metadata": {
        "id": "3cef0674",
        "outputId": "a7591443-c1c8-4344-ec80-b52b91aae6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.33657750487327576,\n",
            "                'd_src_bridge_loss': 0.04263206571340561,\n",
            "                'd_target_bridge_loss': 0.024829374626278877,\n",
            "                'g_src_bridge_loss': 0.49391111731529236,\n",
            "                'g_target_bridge_loss': 0.4551009237766266,\n",
            "                'src_domain_loss': 0.5293594002723694,\n",
            "                'target_domain_loss': 0.5325483083724976,\n",
            "                'total': 0.34499409794807434}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import GVBHook\n",
        "from pytorch_adapt.layers import ModelWithBridge\n",
        "\n",
        "# Discriminator comes after classifier,\n",
        "# so the input shape is num_classes instead of feature size\n",
        "D_ = torch.nn.Sequential(torch.nn.Linear(10, 1), torch.nn.Flatten(start_dim=0))\n",
        "\n",
        "# Add bridges\n",
        "C_ = ModelWithBridge(C)\n",
        "D_ = ModelWithBridge(D_)\n",
        "C_opt_ = torch.optim.Adam(C_.parameters())\n",
        "D_opt_ = torch.optim.Adam(D_.parameters())\n",
        "\n",
        "hook = GVBHook(opts=[G_opt, C_opt_, D_opt_])\n",
        "\n",
        "models = {\"G\": G, \"C\": C_, \"D\": D_}\n",
        "data = get_data(\n",
        "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
        ")\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff82650",
      "metadata": {
        "id": "eff82650"
      },
      "source": [
        "### Information Maximization (IM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "45fa13b6",
      "metadata": {
        "id": "45fa13b6",
        "outputId": "f4c3790a-dba4-4124-e643-f2c282f21cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.16920050978660583,\n",
            "                'diversity_loss': -2.2921385765075684,\n",
            "                'entropy_loss': 2.122807025909424,\n",
            "                'total': -4.3710071622626856e-05}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import ClassifierHook, TargetDiversityHook, TargetEntropyHook\n",
        "\n",
        "hook = ClassifierHook(\n",
        "    opts=[G_opt, C_opt], post=[TargetEntropyHook(), TargetDiversityHook()]\n",
        ")\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77709eaa",
      "metadata": {
        "id": "77709eaa"
      },
      "source": [
        "### [Information-Theoretical Learning of Discriminative Clusters for Unsupervised Domain Adaptation](https://icml.cc/2012/papers/566.pdf) (ITL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4a9a8079",
      "metadata": {
        "id": "4a9a8079",
        "outputId": "db124660-c411-4d51-f7bd-dcc6b8543045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.1202351301908493,\n",
            "                'diversity_loss': -2.2917556762695312,\n",
            "                'entropy_loss': 2.1037609577178955,\n",
            "                'ist_loss': -1.8626447051417472e-09,\n",
            "                'total': -0.016939878463745117}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import (\n",
        "    ClassifierHook,\n",
        "    ISTLossHook,\n",
        "    TargetDiversityHook,\n",
        "    TargetEntropyHook,\n",
        ")\n",
        "\n",
        "hook = ClassifierHook(\n",
        "    opts=[G_opt, C_opt],\n",
        "    post=[ISTLossHook(), TargetEntropyHook(), TargetDiversityHook()],\n",
        ")\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data(\n",
        "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
        ")\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32666c0e",
      "metadata": {
        "id": "32666c0e"
      },
      "source": [
        "### [Deep Transfer Learning with Joint Adaptation Networks](https://arxiv.org/abs/1605.06636) (JMMD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6e68d2d4",
      "metadata": {
        "id": "6e68d2d4",
        "outputId": "39335194-0941-4f92-b1b4-62980a8581bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.08655861020088196,\n",
            "                'joint_confusion_loss': 0.12583012878894806,\n",
            "                'total': 0.10619436949491501}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import AlignerPlusCHook, JointAlignerHook\n",
        "from pytorch_adapt.layers import MMDLoss\n",
        "from pytorch_adapt.layers.utils import get_kernel_scales\n",
        "\n",
        "kernel_scales = get_kernel_scales(low=-3, high=3, num_kernels=10)\n",
        "loss_fn = MMDLoss(kernel_scales=kernel_scales)\n",
        "aligner_hook = JointAlignerHook(loss_fn=loss_fn)\n",
        "hook = AlignerPlusCHook(opts=[G_opt, C_opt], aligner_hook=aligner_hook)\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6990ef",
      "metadata": {
        "id": "2e6990ef"
      },
      "source": [
        "### [Minimum Class Confusion for Versatile Domain Adaptation](https://arxiv.org/abs/1912.03699) (MCC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4b946789",
      "metadata": {
        "id": "4b946789",
        "outputId": "7ca08df9-1664-481b-9a12-5e3fce4e6182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.06311061233282089,\n",
            "                'mcc_loss': 0.8397989273071289,\n",
            "                'total': 0.451454758644104}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import ClassifierHook, MCCHook\n",
        "\n",
        "hook = ClassifierHook(opts=[G_opt, C_opt], post=[MCCHook()])\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ee26432",
      "metadata": {
        "id": "6ee26432"
      },
      "source": [
        "### [Maximum Classifier Discrepancy for Unsupervised Domain Adaptation](https://arxiv.org/abs/1712.02560) (MCD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "64b6b425",
      "metadata": {
        "id": "64b6b425",
        "outputId": "a77fde91-baa8-495b-c483-a82cdc66b3f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x_loss': {'c_loss0': 0.04653286188840866,\n",
            "            'c_loss1': 2.8394877910614014,\n",
            "            'total': 1.4430103302001953},\n",
            " 'y_loss': {'c_loss0': 0.03436530381441116,\n",
            "            'c_loss1': 2.650433301925659,\n",
            "            'discrepancy_loss': -0.07384142279624939,\n",
            "            'total': 0.870319128036499},\n",
            " 'z_loss': {'discrepancy_loss': 0.075227752327919, 'total': 0.075227752327919}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import MCDHook\n",
        "from pytorch_adapt.layers import MultipleModels\n",
        "from pytorch_adapt.utils import common_functions as c_f\n",
        "\n",
        "# MCD needs 2 classifiers\n",
        "C_ = MultipleModels(C, c_f.reinit(copy.deepcopy(C)))\n",
        "C_opt_ = torch.optim.Adam(C_.parameters())\n",
        "\n",
        "hook = MCDHook(g_opts=[G_opt], c_opts=[C_opt_])\n",
        "\n",
        "models = {\"G\": G, \"C\": C_}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8d1a27",
      "metadata": {
        "id": "5b8d1a27"
      },
      "source": [
        "### [Learning Transferable Features with Deep Adaptation Networks](https://arxiv.org/abs/1502.02791) (MMD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b08fc74f",
      "metadata": {
        "id": "b08fc74f",
        "outputId": "faa3224c-b69c-4173-b7fa-52ee2b399f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.015743529424071312,\n",
            "                'features_confusion_loss': 0.005411505699157715,\n",
            "                'logits_confusion_loss': 0.1700156331062317,\n",
            "                'total': 0.06372355669736862}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import AlignerPlusCHook\n",
        "from pytorch_adapt.layers import MMDLoss\n",
        "from pytorch_adapt.layers.utils import get_kernel_scales\n",
        "\n",
        "kernel_scales = get_kernel_scales(low=-3, high=3, num_kernels=10)\n",
        "loss_fn = MMDLoss(kernel_scales=kernel_scales)\n",
        "hook = AlignerPlusCHook(opts=[G_opt, C_opt], loss_fn=loss_fn)\n",
        "\n",
        "models = {\"G\": G, \"C\": C}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df038b68",
      "metadata": {
        "id": "df038b68"
      },
      "source": [
        "### [Unsupervised Domain Adaptation with Residual Transfer Networks](https://arxiv.org/abs/1602.04433) (RTN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "04ff5335",
      "metadata": {
        "id": "04ff5335",
        "outputId": "5a5c5813-3bce-44d1-916d-ed4a35b9c2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_loss': {'c_loss': 0.04441383108496666,\n",
            "                'entropy_loss': 1.8927198648452759,\n",
            "                'features_confusion_loss': 0.17413365840911865,\n",
            "                'total': 0.703755795955658}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import RTNHook\n",
        "from pytorch_adapt.layers import PlusResidual, RandomizedDotProduct\n",
        "\n",
        "residual_model = PlusResidual(torch.nn.Linear(10, 10))\n",
        "feature_combiner = RandomizedDotProduct(in_dims=[100, 10], out_dim=100)\n",
        "\n",
        "kernel_scales = get_kernel_scales(low=-3, high=3, num_kernels=10)\n",
        "loss_fn = MMDLoss(kernel_scales=kernel_scales)\n",
        "hook = RTNHook(opts=[G_opt, C_opt], aligner_loss_fn=loss_fn)\n",
        "\n",
        "models = {\n",
        "    \"G\": G,\n",
        "    \"C\": C,\n",
        "    \"residual_model\": residual_model,\n",
        "    \"feature_combiner\": feature_combiner,\n",
        "}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06a6f032",
      "metadata": {
        "id": "06a6f032"
      },
      "source": [
        "### [Stochastic Classifiers for Unsupervised Domain Adaptation](https://xiatian-zhu.github.io/papers/LuEtAl_CVPR2020.pdf) (STAR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "35fccd53",
      "metadata": {
        "id": "35fccd53",
        "outputId": "ab3c512f-1ec8-4bcd-dd57-351f276089d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x_loss': {'c_loss0': 6.110048294067383,\n",
            "            'c_loss1': 7.3721818923950195,\n",
            "            'total': 6.741115093231201},\n",
            " 'y_loss': {'c_loss0': 5.647284507751465,\n",
            "            'c_loss1': 5.274874687194824,\n",
            "            'discrepancy_loss': -0.12871317565441132,\n",
            "            'total': 3.5978152751922607},\n",
            " 'z_loss': {'discrepancy_loss': 0.11849485337734222,\n",
            "            'total': 0.11849485337734222}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import MCDHook\n",
        "from pytorch_adapt.layers import MultipleModels, StochasticLinear\n",
        "\n",
        "# Use same model twice because the multiple models\n",
        "# is actually modeled by the distribution learned\n",
        "# in StochasticLinear\n",
        "C_ = StochasticLinear(100, 10)\n",
        "C_ = MultipleModels(C_, C_)\n",
        "C_opt_ = torch.optim.Adam(C_.parameters())\n",
        "\n",
        "hook = MCDHook(g_opts=[G_opt], c_opts=[C_opt_])\n",
        "\n",
        "models = {\"G\": G, \"C\": C_}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ccfe018",
      "metadata": {
        "id": "5ccfe018"
      },
      "source": [
        "### [Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation](https://arxiv.org/abs/1903.04064) (SWD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "258da80c",
      "metadata": {
        "id": "258da80c",
        "outputId": "8b73867a-6cf0-4f77-afd4-f1912ff09534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x_loss': {'c_loss0': 0.009857219643890858,\n",
            "            'c_loss1': 2.4092624187469482,\n",
            "            'total': 1.2095597982406616},\n",
            " 'y_loss': {'c_loss0': 0.00883272010833025,\n",
            "            'c_loss1': 2.2350099086761475,\n",
            "            'discrepancy_loss': -0.2507260739803314,\n",
            "            'total': 0.6643721461296082},\n",
            " 'z_loss': {'discrepancy_loss': 0.1385493129491806,\n",
            "            'total': 0.1385493129491806}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import MCDHook\n",
        "from pytorch_adapt.layers import MultipleModels, SlicedWasserstein\n",
        "from pytorch_adapt.utils import common_functions as c_f\n",
        "\n",
        "# MCD needs 2 classifiers\n",
        "C_ = MultipleModels(C, c_f.reinit(copy.deepcopy(C)))\n",
        "C_opt_ = torch.optim.Adam(C_.parameters())\n",
        "loss_fn = SlicedWasserstein(m=128)\n",
        "\n",
        "hook = MCDHook(g_opts=[G_opt], c_opts=[C_opt_], discrepancy_loss_fn=loss_fn)\n",
        "\n",
        "models = {\"G\": G, \"C\": C_}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed1ded4",
      "metadata": {
        "id": "7ed1ded4"
      },
      "source": [
        "### [Domain-Symmetric Networks for Adversarial Domain Adaptation](https://arxiv.org/abs/1904.04663) (SymNets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "49062eb5",
      "metadata": {
        "id": "49062eb5",
        "outputId": "1b88a137-801b-4f85-ece7-cd65804ae1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'c_loss': {'c_loss0': 0.008523832075297832,\n",
            "            'c_loss1': 2.7464451789855957,\n",
            "            'c_symnets_src_domain_loss_0': 0.021570373326539993,\n",
            "            'c_symnets_target_domain_loss_1': 0.8368582725524902,\n",
            "            'total': 0.9033494591712952},\n",
            " 'g_loss': {'g_symnets_target_domain_loss_0': 0.6074486374855042,\n",
            "            'g_symnets_target_domain_loss_1': 0.8207646608352661,\n",
            "            'symnets_category_loss': 3.787899971008301,\n",
            "            'symnets_entropy_loss': 2.089550018310547,\n",
            "            'total': 1.826415777206421}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import SymNetsHook\n",
        "from pytorch_adapt.layers import MultipleModels\n",
        "from pytorch_adapt.utils import common_functions as c_f\n",
        "\n",
        "# SymNets needs 2 classifiers\n",
        "C_ = MultipleModels(C, c_f.reinit(copy.deepcopy(C)))\n",
        "C_opt_ = torch.optim.Adam(C_.parameters())\n",
        "\n",
        "hook = SymNetsHook(g_opts=[G_opt], c_opts=[C_opt_])\n",
        "\n",
        "models = {\"G\": G, \"C\": C_}\n",
        "data = get_data([\"src_imgs\", \"target_imgs\", \"src_labels\"])\n",
        "_, losses = hook({**models, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9edd1ee",
      "metadata": {
        "id": "f9edd1ee"
      },
      "source": [
        "### [A DIRT-T Approach to Unsupervised Domain Adaptation](https://arxiv.org/abs/1802.08735) (VADA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "43dba151",
      "metadata": {
        "id": "43dba151",
        "outputId": "7dea8237-6740-40d4-f8a5-2d02f6f172ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d_loss': {'d_src_domain_loss': 0.6249565482139587,\n",
            "            'd_target_domain_loss': 0.6639358401298523,\n",
            "            'total': 0.6444461941719055},\n",
            " 'g_loss': {'c_loss': 0.008804281242191792,\n",
            "            'entropy_loss': 1.896783471107483,\n",
            "            'g_src_domain_loss': 0.6186193227767944,\n",
            "            'g_target_domain_loss': 0.6593835353851318,\n",
            "            'src_vat_loss': 0.3772188723087311,\n",
            "            'target_vat_loss': 1.4838342666625977,\n",
            "            'total': 0.8407739996910095}}\n"
          ]
        }
      ],
      "source": [
        "from pytorch_adapt.hooks import VADAHook\n",
        "\n",
        "combined_model = torch.nn.Sequential(G, C)\n",
        "hook = VADAHook(g_opts=[G_opt, C_opt], d_opts=[D_opt])\n",
        "\n",
        "models = {\"G\": G, \"C\": C, \"D\": D}\n",
        "misc = {\"combined_model\": combined_model}\n",
        "data = get_data(\n",
        "    [\"src_imgs\", \"target_imgs\", \"src_labels\", \"src_domain\", \"target_domain\"]\n",
        ")\n",
        "_, losses = hook({**models, **misc, **data})\n",
        "pprint(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "dfea0c56",
      "metadata": {
        "id": "dfea0c56"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "PaperImplementationsAsHooks.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}